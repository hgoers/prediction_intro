[
  {
    "objectID": "01_massey.html",
    "href": "01_massey.html",
    "title": "The Massey Method",
    "section": "",
    "text": "library(fitzRoy)\nlibrary(tidyverse)\n\n\naflm_2025 &lt;- fetch_results(season = 2025, round_number = 0:2, comp = \"AFLM\") |&gt; \n  select(round = round.name,\n         home_team = match.homeTeam.name, \n         away_team = match.awayTeam.name,\n         home_team_score = homeTeamScore.matchScore.totalScore,\n         away_team_score = awayTeamScore.matchScore.totalScore) |&gt; \n  rowwise() |&gt; \n  mutate(match_id = paste(sort(c(home_team, away_team)), collapse = \" vs \"))\n\nteams &lt;- aflm_2025 |&gt; \n  pivot_longer(home_team:away_team, values_to = \"team\") |&gt; \n  distinct(team) |&gt; \n  arrange(team)\n\nAs an undergraduate, Kenneth Massey came up with a method for ranking college football teams. An adaptation of this very method would later become one of the methods used by the Bowl Championship Series system to select NCAA football bowl match-ups. Not bad for an undergraduate honors thesis!\nThe Massey Method uses the point differential of all games played by teams in a league to generate a rating for each team. The fundamental idea is that the difference between the ratings of two teams should predict the point differential in a game between them.\nFor a league with n teams, the method sets up a system of n linear equations with n unknown ratings (r1​,r2​,…,rn​). This system of equations is represented in matrix form as:\n\\[\nMr = p\n\\]\nWhere:\n\n\\(M\\) is the Massey Matrix\n\\(r\\) is the vector of unknown team ratings\n\\(p\\) is the vector of each team’s total point differential\n\nWe don’t know the teams’ ratings (\\(r\\)): that’s what we are trying to calculate. So, we need to calculate \\(M\\) and \\(p\\). This will allow us to calculate their rankings.\nLet’s start with each team’s total point differential (\\(p\\)). First, we list the teams and find each team’s differential, which is simply the total points scored minus the total points allowed across all games. For Round 1, this is simply the number of points each team won or lost by in their one game.\n\np &lt;- aflm_2025 |&gt; \n  mutate(differential = home_team_score - away_team_score) |&gt; \n  pivot_longer(home_team:away_team, values_to = \"team\") |&gt; \n  mutate(differential = if_else(name == \"away_team\", differential * -1, \n                                differential)) |&gt; \n  group_by(team) |&gt; \n  summarise(differential = sum(differential)) |&gt; \n  arrange(team) |&gt; \n  pull(differential)\n\np\n\n [1]  124   23  -33   45  -87  -81   55   71   87   66  -62   43  -19  -59  -56\n[16]  -21 -106   10\n\n\nNext, we need to construct the Massey Matrix. The Massey Matrix \\(M\\) is a square matrix where:\n\nDiagonal Entries (\\(M_{i,i}\\)): The entry on the main diagonal for a team \\(i\\) is the total number of games that team \\(i\\) has played, which we denote as \\(t_i\\).\nOff-Diagonal Entries (\\(M_{i,j}\\) for \\(i \\ne j\\)): The entry at row \\(i\\) and column \\(j\\) is the negative of the number of times team \\(i\\) played team \\(j\\).\n\n\nn_games_played &lt;- aflm_2025 |&gt; \n  pivot_longer(home_team:away_team, values_to = \"team\") |&gt; \n  count(team) |&gt; \n  arrange(team)",
    "crumbs": [
      "The Massey Method"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "From Polls to Playoffs: The Science of Prediction",
    "section": "",
    "text": "Preface\nSo, you would like to predict the future. This course will introduce you to the skills and knowledge you need to make an informed guess as to what lies ahead.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01_whole_game.html",
    "href": "01_whole_game.html",
    "title": "1  The Whole Game",
    "section": "",
    "text": "1.1 A Forecasting Roadmap\nForecasting is the art and science of predicting the future. In political science, we can use it to better understand elections, the impact of policies, international conflict, and public opinion. In this course, you will learn how to move beyond simple guesswork and create structured, data-driven predictions—a skill invaluable in academia, government, and the private sector.\nThink about the high-stakes world of modern politics. Every campaign manager, pundit, and policy analyst desperately wants to know what will happen next. Will a new policy boost a leader’s popularity? Will a major news event sink a campaign? We can’t know for certain, but we can manage our uncertainty by building powerful statistical models that learn from history.\nThis introductory chapter provides a high-level roadmap of the entire forecasting process, from raw data to final prediction. Each step outlined here corresponds to a major topic we will dive into in later chapters. By the end of this course, you will be able to perform this entire process confidently and critique the forecasts you see every day in the news.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#prepare-your-data",
    "href": "01_whole_game.html#prepare-your-data",
    "title": "1  The Whole Game - A Forecasting Roadmap",
    "section": "1.2 Prepare your data",
    "text": "1.2 Prepare your data\nYou first need to prepare your data for analysis. This can often be the most time-consuming part of your data analysis process. Happily, I have cleaned our data for you.\nThe last step in this process is to convert your data set into a tsibble object, which has features that make time-series analysis easier.\n\ntrump_approval &lt;- read_rds(here::here(\"data\", \"trump_approval.rds\")) |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tsibble()\n\ntrump_approval\n\n# A tsibble: 36 x 2 [1W]\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W05      49\n 2 2025 W06      46\n 3 2025 W07      46\n 4 2025 W08      50\n 5 2025 W09      48\n 6 2025 W10      48\n 7 2025 W11      47\n 8 2025 W12      45\n 9 2025 W13      48\n10 2025 W14      46\n# ℹ 26 more rows",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game - A Forecasting Roadmap</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#plot-your-data",
    "href": "01_whole_game.html#plot-your-data",
    "title": "1  The Whole Game - A Forecasting Roadmap",
    "section": "1.3 Plot your data",
    "text": "1.3 Plot your data\nNext, you should plot your data. This will allow you to get a sense of the overall pattern of your data across time. What is the overall pattern? Do you see any repeated patterns across time? Figure 4.1 shows Mr Trump’s approval rating since his first day in office.\n\nautoplot(trump_approval) + \n  theme_minimal() + \n  labs(x = \"Date\",\n       y = \"Approval rating (%)\",\n       caption = \"Data source: The Economist/YouGov\") + \n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\nFigure 1.1: Mr Trump’s approval ratings since entering his second term in office.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game - A Forecasting Roadmap</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#specify-your-model",
    "href": "01_whole_game.html#specify-your-model",
    "title": "1  The Whole Game - A Forecasting Roadmap",
    "section": "1.4 Specify your model",
    "text": "1.4 Specify your model\nNext you need to specify an appropriate model for your data. There are many different models from which you can select. We will discuss several in this course.\nFor now, I will select a simple model: a linear trend model (which we will discuss in detail shortly).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game - A Forecasting Roadmap</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#train-your-model",
    "href": "01_whole_game.html#train-your-model",
    "title": "1  The Whole Game - A Forecasting Roadmap",
    "section": "1.5 Train your model",
    "text": "1.5 Train your model\nNext, you need to train your selected model on your data. For example, to train my linear trend model, I will run the following:\n\nfit &lt;- trump_approval |&gt; \n  model(linear_trend = TSLM(approve ~ trend()))\n\nI now have a linear trend model of Mr Trump’s approval rating over time.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game - A Forecasting Roadmap</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#evaluate-your-models-performance",
    "href": "01_whole_game.html#evaluate-your-models-performance",
    "title": "1  The Whole Game - A Forecasting Roadmap",
    "section": "1.6 Evaluate your model’s performance",
    "text": "1.6 Evaluate your model’s performance\nNext, you should see how well your model performs on data on which it has not been trained. Can it accurately predict data it has never before seen?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game - A Forecasting Roadmap</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#forecast",
    "href": "01_whole_game.html#forecast",
    "title": "1  The Whole Game - A Forecasting Roadmap",
    "section": "1.7 Forecast",
    "text": "1.7 Forecast\nIf you are happy with your model, you can use it to predict future values. For example, I am now going to forecast Mr Trump’s approval ratings for the next five weeks using my linear trend model:\n\ntrump_approval_forecast &lt;- forecast(fit, h = \"5 weeks\")\ntrump_approval_forecast\n\n# A fable: 5 x 4 [1W]\n# Key:     .model [1]\n  .model           date\n  &lt;chr&gt;          &lt;week&gt;\n1 linear_trend 2025 W41\n2 linear_trend 2025 W42\n3 linear_trend 2025 W43\n4 linear_trend 2025 W44\n5 linear_trend 2025 W45\n# ℹ 2 more variables: approve &lt;dist&gt;, .mean &lt;dbl&gt;\n\n\nI now have my forecast of Mr Trump’s approval rating for the next five weeks (each row corresponds to one week’s forecast). I have estimated a range of plausible values of his approval rating (approve). My point estimate is the center of this plausible range (.mean).\nIt can be helpful to look at these predicted approval ratings in their context. Let’s plot them alongside his approval ratings so far:\n\ntrump_approval_forecast |&gt; \n  autoplot(trump_approval) + \n  theme_minimal() + \n  labs(x = \"Date\",\n       y = \"Approval rating (%)\",\n       caption = \"Data source: The Economist/YouGov\") + \n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\nFigure 1.2: Mr Trump’s approval ratings, both observed and predicted.\n\n\n\n\n\nOur simple model predicts that Mr Trump’s declining popularity will continue despite the brief up-tick he appeared to enjoy last week.\nThis course introduces the skills you need to make predictions informed by what has happened in the past. Let’s get started!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game - A Forecasting Roadmap</span>"
    ]
  },
  {
    "objectID": "02_forecasting.html",
    "href": "02_forecasting.html",
    "title": "2  The Forecasting Landscape",
    "section": "",
    "text": "2.1 What Can Be Forecast?\nWelcome to the world of predictive analytics! If you’ve ever tried to guess who will win the World Series, what the Fed will do with interest rates, or whether a piece of legislation will pass, you’ve been forecasting. The difference is that now, we move from intuition to structured science.\nThis chapter is designed to broaden your perspective. Forecasting is not just about time series—it’s about applying rigorous statistical methods to nearly any outcome with quantifiable uncertainty. By the end of this module, you will understand the massive scope of modern forecasting, its key terminology, and the foundational role of data in political and sports analysis.\nForecasting applies to anything that moves, changes, and is measurable. If you can collect data on it, you can model it, and therefore, you can forecast it. The goal is always to manage uncertainty, not eliminate it.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Forecasting Landscape</span>"
    ]
  },
  {
    "objectID": "02_forecasting.html#the-statistics-of-forecasting",
    "href": "02_forecasting.html#the-statistics-of-forecasting",
    "title": "2  Introduction to Forecasting",
    "section": "2.2 The statistics of forecasting",
    "text": "2.2 The statistics of forecasting",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to Forecasting</span>"
    ]
  },
  {
    "objectID": "03_time_series.html",
    "href": "03_time_series.html",
    "title": "3  Introduction to Time Series in R",
    "section": "",
    "text": "3.1 tsibble objects\nA lot of interesting questions involve trends over time. From presidential approval ratings to your favorite team’s performance in a season, we are often more interested in trends than single data points.\nThe easiest way to handle time series data in R is as a tsibble object. For example, here is a normal tibble of Mr Trump’s approval ratings across his current term in office:\ntrump_approval &lt;- read_rds(here::here(\"data\", \"trump_approval.rds\"))\ntrump_approval\n\n# A tibble: 36 × 2\n   date       approve\n   &lt;date&gt;       &lt;dbl&gt;\n 1 2025-09-29      40\n 2 2025-09-22      39\n 3 2025-09-15      39\n 4 2025-09-08      41\n 5 2025-09-02      41\n 6 2025-08-04      41\n 7 2025-08-25      41\n 8 2025-08-18      40\n 9 2025-08-11      42\n10 2025-07-07      42\n# ℹ 26 more rows\nThese data are actually collected on a weekly basis by YouGov on behalf of The Economist. Although they have very good coverage, they do miss some weeks. It is difficult to see that these are weekly data and where our coverage is missing in this current format.\nSo, let’s convert it to a tsibble:\ntrump_approval_ts &lt;- trump_approval |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tsibble()\n\ntrump_approval_ts\n\n# A tsibble: 36 x 2 [1W]\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W05      49\n 2 2025 W06      46\n 3 2025 W07      46\n 4 2025 W08      50\n 5 2025 W09      48\n 6 2025 W10      48\n 7 2025 W11      47\n 8 2025 W12      45\n 9 2025 W13      48\n10 2025 W14      46\n# ℹ 26 more rows\nMuch better! The tsibble handles the “timing” of it all much more nicely than a standard tibble. By converting the date column to weekly data using the yearweek() function and the data set itself into a tsibble object, I have ensured that any visualizations or models I build using these data will be treated appropriately.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Time Series in R</span>"
    ]
  },
  {
    "objectID": "03_time_series.html#tsibble-objects",
    "href": "03_time_series.html#tsibble-objects",
    "title": "3  Introduction to Time Series in R",
    "section": "",
    "text": "3.1.1 Indexes\nThe column that records the time of your observations is referred to as the index. as_tibble() will often do a good job of guessing which column should be treated as your index, but you can specify it directly using the index argument. For examle:\n\ntrump_approval |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tibble(index = date)\n\n# A tibble: 36 × 2\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W40      40\n 2 2025 W39      39\n 3 2025 W38      39\n 4 2025 W37      41\n 5 2025 W36      41\n 6 2025 W32      41\n 7 2025 W35      41\n 8 2025 W34      40\n 9 2025 W33      42\n10 2025 W28      42\n# ℹ 26 more rows\n\n\ntsibble objects can handle many different frequencies:\n\n\n\n\n\nFrequency\nFunction\n\n\n\n\nYearly\nyear()\n\n\nQuarterly\nyearquarter()\n\n\nMonthly\nyearmonth()\n\n\nWeekly\nyearweek()\n\n\nDaily\nSee: as_date()\n\n\nSub-daily\nSee as_datetime()\n\n\n\n\n\n\n\n3.1.2 Keys\ntsibble objects are also very good at handling multiple groups within your data. For example, you might have data on all teams in a league. It can be useful to group those data by team.\nBelow is data on each AFL team’s performance throughout the 2024 season. For example, we have data on their position in the ladder throughout the season (ladder_position), the cumulative number of points they have scored (score_for) and have had scored against them (score_against).\nThere were 25 rounds in the regular season (excluding finals). Those rounds are my index. I want to track each team’s performance across the season. Therefore, my key is the team.\n\nafl_ladder &lt;- read_rds(here::here(\"data\", \"afl_ladder.rds\"))\n\nafl_ladder_ts &lt;- as_tsibble(afl_ladder, key = team, index = round_number)\nafl_ladder_ts\n\n# A tsibble: 450 x 8 [1]\n# Key:       team [18]\n   season team     round_number season_points score_for score_against percentage\n    &lt;dbl&gt; &lt;chr&gt;           &lt;int&gt;         &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n 1   2024 Adelaide            1             0         0             0      0    \n 2   2024 Adelaide            2             0        54            60      0.9  \n 3   2024 Adelaide            3             0       131           156      0.840\n 4   2024 Adelaide            4             0       165           225      0.733\n 5   2024 Adelaide            5             0       228           303      0.752\n 6   2024 Adelaide            6             4       328           401      0.818\n 7   2024 Adelaide            7             4       403           479      0.841\n 8   2024 Adelaide            8             8       541           560      0.966\n 9   2024 Adelaide            9            12       619           608      1.02 \n10   2024 Adelaide           10            14       709           698      1.02 \n# ℹ 440 more rows\n# ℹ 1 more variable: ladder_position &lt;int&gt;\n\n\nNotice that the tsibble object prints my key above the the data set. It recognizes that there are 18 different groups (teams) in my key. I now have 18 different time series (each team’s performance across the season) stored in one convenient data set. I can look at overall trends and compare the 18 different teams’ performance easily.\n\n\n3.1.3 Working with tsibble objects\nOn a tsibble, we can use all of the functions that you can use on a normal tibble or data.frame object. They are set up with the tidyverse in mind, so functions in that family work seamlessly.\nFor example, I can filter my data set of Mr Trump’s approval rating to look only at his approval in weeks five to 10 of his current term1:\n\nfilter(trump_approval_ts, date &lt;= yearweek(\"2025 W10\"))\n\n# A tsibble: 6 x 2 [1W]\n      date approve\n    &lt;week&gt;   &lt;dbl&gt;\n1 2025 W05      49\n2 2025 W06      46\n3 2025 W07      46\n4 2025 W08      50\n5 2025 W09      48\n6 2025 W10      48\n\n\nI can also quickly calculate Mr Trump’s average approval rating across his term in office:\n\nsummarise(trump_approval_ts, avg_approve = mean(approve))\n\n# A tsibble: 36 x 2 [1W]\n       date avg_approve\n     &lt;week&gt;       &lt;dbl&gt;\n 1 2025 W05          49\n 2 2025 W06          46\n 3 2025 W07          46\n 4 2025 W08          50\n 5 2025 W09          48\n 6 2025 W10          48\n 7 2025 W11          47\n 8 2025 W12          45\n 9 2025 W13          48\n10 2025 W14          46\n# ℹ 26 more rows",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Time Series in R</span>"
    ]
  },
  {
    "objectID": "03_time_series.html#working-with-tsibble-objects",
    "href": "03_time_series.html#working-with-tsibble-objects",
    "title": "3  Introduction to Time Series",
    "section": "3.2 Working with tsibble objects",
    "text": "3.2 Working with tsibble objects\nOn a tsibble, we can use all of the functions that you can use on a normal tibble or data.frame object. They are set up with the tidyverse in mind, so functions in that family work seamlessly.\nFor example, I can filter my data set of Mr Trump’s approval rating to look only at his approval in weeks five to 10 of his current term1:\n\nfilter(trump_approval_ts, date &lt;= yearweek(\"2025 W10\"))\n\n# A tsibble: 6 x 2 [1W]\n      date approve\n    &lt;week&gt;   &lt;dbl&gt;\n1 2025 W05      49\n2 2025 W06      46\n3 2025 W07      46\n4 2025 W08      50\n5 2025 W09      48\n6 2025 W10      48\n\n\nI can also quickly calculate Mr Trump’s average approval rating across his term in office:\n\nsummarise(trump_approval_ts, avg_approve = mean(approve))\n\n# A tsibble: 36 x 2 [1W]\n       date avg_approve\n     &lt;week&gt;       &lt;dbl&gt;\n 1 2025 W05          49\n 2 2025 W06          46\n 3 2025 W07          46\n 4 2025 W08          50\n 5 2025 W09          48\n 6 2025 W10          48\n 7 2025 W11          47\n 8 2025 W12          45\n 9 2025 W13          48\n10 2025 W14          46\n# ℹ 26 more rows",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Time Series</span>"
    ]
  },
  {
    "objectID": "03_time_series.html#footnotes",
    "href": "03_time_series.html#footnotes",
    "title": "3  Introduction to Time Series in R",
    "section": "",
    "text": "The poll only started after his fifth week in office.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Time Series in R</span>"
    ]
  },
  {
    "objectID": "03_time_series.html#plotting-your-data",
    "href": "03_time_series.html#plotting-your-data",
    "title": "3  Introduction to Time Series in R",
    "section": "3.2 Plotting your data",
    "text": "3.2 Plotting your data\nPatterns in our data are often most easily detected when we visualize them. The simplest plot to start with is a time series plot. The ggtime R package provides a series of functions that make visualizing time series data simple.\nFor example, Figure 3.1 shows Mr Trump’s approval ratings across his current term.\n\nautoplot(trump_approval_ts) + \n  theme_minimal() + \n  labs(x = \"Date\",\n       y = \"Approval rating (%)\",\n       caption = \"Data source: The Economist/YouGov\") + \n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\nFigure 3.1: Mr Trump’s approval ratings since entering his second term in office.\n\n\n\n\n\nWe can see that Mr Trump’s popularity is declining. In fact, he has not yet enjoyed more than 50 percent of the US voting public’s approval.\n\n3.2.1 Plotting grouped data\nWe can also plot grouped data to more easily make comparisons between them. For example, Figure 3.2 plots each of the 18 AFL teams’ score percentages across the 2024 season. Some teams, including long-suffering North Melbourne, never managed to score more points than they conceded. Other teams, including the Sydney Swans, managed to never dip below 100 percent.\n\nautoplot(afl_ladder_ts, percentage) + \n  geom_hline(yintercept = 1, linetype = \"dashed\") +\n  theme_minimal() + \n  labs(x = \"Round\",\n       y = \"Scoring percentage\",\n       caption = \"Data source: AFL Tables\") + \n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\nFigure 3.2: AFL teams’ score percentage across the 2024 regular season.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Time Series in R</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html",
    "href": "03_time_series_r.html",
    "title": "3  The Toolkit: R for Time Series",
    "section": "",
    "text": "3.1 The Foundation: The tsibble Object\nYou are already proficient with R and the tidyverse, which gives you a powerful foundation for data manipulation. However, time series data are special. Unlike a standard dataset where each row is independent, in a time series, the order matters. A value today is highly dependent on the value yesterday.\nTo handle this dependency and make forecasting efficient and error-free, the R community has developed a specialized ecosystem of packages collectively known as the fable framework.\nThis chapter introduces the four core tools you will use in this course:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#tsibble-objects",
    "href": "03_time_series_r.html#tsibble-objects",
    "title": "3  The Toolkit: R for Time Series",
    "section": "",
    "text": "3.1.1 Indexes\nThe column that records the time of your observations is referred to as the index. as_tibble() will often do a good job of guessing which column should be treated as your index, but you can specify it directly using the index argument. For examle:\n\ntrump_approval |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tibble(index = date)\n\n# A tibble: 38 × 2\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W42      40\n 2 2025 W41      39\n 3 2025 W40      40\n 4 2025 W39      39\n 5 2025 W37      41\n 6 2025 W36      41\n 7 2025 W38      39\n 8 2025 W32      41\n 9 2025 W35      41\n10 2025 W34      40\n# ℹ 28 more rows\n\n\ntsibble objects can handle many different frequencies:\n\n\n\n\n\nFrequency\nFunction\n\n\n\n\nYearly\nyear()\n\n\nQuarterly\nyearquarter()\n\n\nMonthly\nyearmonth()\n\n\nWeekly\nyearweek()\n\n\nDaily\nSee: as_date()\n\n\nSub-daily\nSee as_datetime()\n\n\n\n\n\n\n\n3.1.2 Keys\ntsibble objects are also very good at handling multiple groups within your data. For example, you might have data on all teams in a league. It can be useful to group those data by team.\nBelow is data on each AFL team’s performance throughout the 2024 season. For example, we have data on their position in the ladder throughout the season (ladder_position), the cumulative number of points they have scored (score_for) and have had scored against them (score_against).\nThere were 25 rounds in the regular season (excluding finals). Those rounds are my index. I want to track each team’s performance across the season. Therefore, my key is the team.\n\nafl_ladder &lt;- read_rds(here::here(\"data\", \"afl_ladder.rds\"))\n\nafl_ladder_ts &lt;- as_tsibble(afl_ladder, key = team, index = round_number)\nafl_ladder_ts\n\n# A tsibble: 450 x 8 [1]\n# Key:       team [18]\n   season team     round_number season_points score_for score_against percentage\n    &lt;dbl&gt; &lt;chr&gt;           &lt;int&gt;         &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n 1   2024 Adelaide            1             0         0             0      0    \n 2   2024 Adelaide            2             0        54            60      0.9  \n 3   2024 Adelaide            3             0       131           156      0.840\n 4   2024 Adelaide            4             0       165           225      0.733\n 5   2024 Adelaide            5             0       228           303      0.752\n 6   2024 Adelaide            6             4       328           401      0.818\n 7   2024 Adelaide            7             4       403           479      0.841\n 8   2024 Adelaide            8             8       541           560      0.966\n 9   2024 Adelaide            9            12       619           608      1.02 \n10   2024 Adelaide           10            14       709           698      1.02 \n# ℹ 440 more rows\n# ℹ 1 more variable: ladder_position &lt;int&gt;\n\n\nNotice that the tsibble object prints my key above the the data set. It recognizes that there are 18 different groups (teams) in my key. I now have 18 different time series (each team’s performance across the season) stored in one convenient data set. I can look at overall trends and compare the 18 different teams’ performance easily.\n\n\n3.1.3 Working with tsibble objects\nOn a tsibble, we can use all of the functions that you can use on a normal tibble or data.frame object. They are set up with the tidyverse in mind, so functions in that family work seamlessly.\nFor example, I can filter my data set of Mr Trump’s approval rating to look only at his approval in weeks five to 10 of his current term1:\n\nfilter(trump_approval_ts, date &lt;= yearweek(\"2025 W10\"))\n\n# A tsibble: 6 x 2 [1W]\n      date approve\n    &lt;week&gt;   &lt;dbl&gt;\n1 2025 W05      49\n2 2025 W06      46\n3 2025 W07      46\n4 2025 W08      50\n5 2025 W09      48\n6 2025 W10      48\n\n\nI can also quickly calculate Mr Trump’s average approval rating across his term in office:\n\nsummarise(trump_approval_ts, avg_approve = mean(approve))\n\n# A tsibble: 38 x 2 [1W]\n       date avg_approve\n     &lt;week&gt;       &lt;dbl&gt;\n 1 2025 W05          49\n 2 2025 W06          46\n 3 2025 W07          46\n 4 2025 W08          50\n 5 2025 W09          48\n 6 2025 W10          48\n 7 2025 W11          47\n 8 2025 W12          45\n 9 2025 W13          48\n10 2025 W14          46\n# ℹ 28 more rows",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#plotting-your-data",
    "href": "03_time_series_r.html#plotting-your-data",
    "title": "3  Introduction to Time Series in R",
    "section": "3.2 Plotting your data",
    "text": "3.2 Plotting your data\nPatterns in our data are often most easily detected when we visualize them. The simplest plot to start with is a time series plot. The ggtime R package provides a series of functions that make visualizing time series data simple.\nFor example, Figure 4.1 shows Mr Trump’s approval ratings across his current term.\n\nautoplot(trump_approval_ts) + \n  theme_minimal() + \n  labs(x = \"Date\",\n       y = \"Approval rating (%)\",\n       caption = \"Data source: The Economist/YouGov\") + \n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\nFigure 3.1: Mr Trump’s approval ratings since entering his second term in office.\n\n\n\n\n\nWe can see that Mr Trump’s popularity is declining. In fact, he has not yet enjoyed more than 50 percent of the US voting public’s approval.\n\n3.2.1 Plotting grouped data\nWe can also plot grouped data to more easily make comparisons between them. For example, Figure 3.2 plots each of the 18 AFL teams’ score percentages across the 2024 season. Some teams, including long-suffering North Melbourne, never managed to score more points than they conceded. Other teams, including the Sydney Swans, managed to never dip below 100 percent.\n\nautoplot(afl_ladder_ts, percentage) + \n  geom_hline(yintercept = 1, linetype = \"dashed\") +\n  theme_minimal() + \n  labs(x = \"Round\",\n       y = \"Scoring percentage\",\n       caption = \"Data source: AFL Tables\") + \n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\nFigure 3.2: AFL teams’ score percentage across the 2024 regular season.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Introduction to Time Series in R</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#footnotes",
    "href": "03_time_series_r.html#footnotes",
    "title": "3  The Toolkit: R for Time Series",
    "section": "",
    "text": "The poll only started after his fifth week in office.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "04_time_series.html",
    "href": "04_time_series.html",
    "title": "4  Finding Patterns Over Time",
    "section": "",
    "text": "4.1 Trends\nAt this early stage, we will focus on the skills and knowledge needed to explore and formalize the relationship between our outcome of interest and time itself. Is the President’s approval rating increasing or decreasing the longer they stay in office? Are there meaningful differences between voter turnout in mid-term elections compared to presidential ones? Is it true that we are seeing fewer and fewer .300 hitters in the modern game? Once we have a handle on historical trends and patterns in our data, we will move on to using that information to make informed predictions about what comes next.\nLet’s take another look at Mr Trump’s approval rating over his current term in office, which is shown in Figure 4.1. If I asked you to summarize how his popularity was tracking, what would you say?\nFigure 4.1: Mr Trump’s approval ratings since entering his second term in office.\nIn general, his approval rating is decreasing. In fact, I can draw a straight line through these data to capture that downward trend, as I have done in Figure 4.2. A trend exists when there is a long-term increase or decrease in the data. We use the trend to describe the general pattern of our data, ignoring small or random fluctuations and noise.\nFigure 4.2: Mr Trump’s approval ratings since entering his second term in office.\nTrends do not need to be linear. For example, Figure 4.3 shows global Gross Domestic Product (GDP) from 1952 to 2007. In general, GDP is growing at an increasing rate. Therefore, its trend is positive and exponential.\nFigure 4.3: Global Gross Domestic Product from 1952 to 2007.\nTrends are useful summaries of the general relationship between your variable of interest and time. By stripping away fluctuations from this general pattern, we gain a better understanding of the broad thrust of our data. We will learn how to do this formally shortly.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#seasonality",
    "href": "04_time_series.html#seasonality",
    "title": "4  Finding Patterns Over Time",
    "section": "",
    "text": "Note\n\n\n\nA cycle occurs when the data exhibit rises and falls that are not of a fixed frequency. The fact that they are not of a fixed frequency is what distinguishes them from seasons.\n\n\n\n\n\n\n\n4.1.1 Relationships between values and time\nWe can more formally identify seasons by looking at the relationship between our values and time itself. A lag plot shows each value plotted against its previous value, lagged by varying time periods. The value is plotted on the y-axis and its corresponding lagged value is plotted on the x-axis.\nFor example, Figure 4.4 is a lag plot of turnout rates to US general elections. The first plot, titled lag 1, plots each election’s turnout rate against the turnout rate of the previous election. So the turnout rate for the 2022 election is plotted (on the y-axis) against the turnout rate for the 2020 election (x-axis). The second plot, titled lag 2, plots each election’s turnout rate against the rate of two elections ago. The turnout rate for the 2022 election is plotted against the turnout rate for the 2018 election.\n\nus_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  gg_lag(vep_turnout_rate, geom = \"point\") + \n  theme_minimal() + \n  labs(x = \"Turnout rate lagged (%)\",\n       y = \"Turnout rate (%)\",\n       caption = \"Data source: University of Florida Election Lab\")\n\n\n\n\n\n\n\nFigure 4.4: Lag plot of US general election turnout rates from 1998 to 2022.\n\n\n\n\n\nOdd numbered lags are, therefore, plotting turnout rates for mid-term and presidential elections against each other (for example, the 2022 mid-term election is plotted against the 2020 presidential election in lag 1). We tend to see two clusters of dots sitting in opposite corners of those graphs (lag 1, 3, 5, 7, and 9). These values are strongly negatively correlated.\nEven numbered lags are plotting like-for-like elections: mid-terms against mid-terms and presidentials against presidentials. We see a strong positive correlation in these plots (lag 2, 4, 6, and 8). The dots are scattered along the horizontal dashed line that represents equal values (a dot would sit on that line if the turnout rates of those two elections were the same).\nStrong correlations between values and their lagged counterparts at regular intervals are evidence of seasonality. We can calculate these correlations using feasts::ACF(). They are called autocorrelations because we are looking for the relationships lurking within the variable itself.\nLet’s look at autocorrelations for up to eight lagged election years:\n\nus_turnout_autocor &lt;- us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  ACF(var = vep_turnout_rate, lag_max = 8)\n\nus_turnout_autocor\n\n# A tsibble: 8 x 3 [2Y]\n# Key:       state [1]\n  state              lag    acf\n  &lt;chr&gt;         &lt;cf_lag&gt;  &lt;dbl&gt;\n1 United States       2Y -0.722\n2 United States       4Y  0.723\n3 United States       6Y -0.756\n4 United States       8Y  0.601\n5 United States      10Y -0.531\n6 United States      12Y  0.479\n7 United States      14Y -0.354\n8 United States      16Y  0.319\n\n\nAs usual, these data are much easier to digest visually. Let’s plot those autocorrelations:\n\nautoplot(us_turnout_autocor)\n\n\n\n\n\n\n\nFigure 4.5\n\n\n\n\n\nWe have formalized our intuition derived from the lag plots above: there is clear seasonality in our data. Voter turnout rates for mid-term and presidential elections are different (mid-term elections tend to be attended by fewer people). They are negatively autocorrelated (hence those lines shooting below 0). Turnout rates for like-elections (mid-term and mid-term, or presidential and presidential) are similar, or positively autocorrelated (hence the lines shoot up from 0).\nWe learn something else from these autocorrelations. Presidential (mid-term) elections that are closer in time to each other have more similar turnout rates. For example, the turnout rates for the 2022 and 2018 mid-term elections are more similar than those of the 2022 and 2002 elections. How do I know this? Well, the autocorrelation coefficient for smaller lags (for example, 1 and 3) are larger than the coefficient of larger lags (for example, 5 and 7). This indicates a trend in our data. Looking back at Figure 4.2, we can see that turnout rates have generally increased over time: a greater proportion of eligible voters tend to vote in more recent elections than they did in the late 90s and early 2000s.\n\n\n4.1.2 White noise\nSure, turnout rates in like elections look alike, but are they really that similar. How confident can we be that they are sufficiently similar to each other?\nFor example, I can make up some data that are genuinely random and still find some patterns within them that might suggest a trend, cycle, or even seasonality. I use rnorm() to randomly sample from a Normal distribution. These data points do not relate to one another. I should find no meaningful patterns within them.\n\nset.seed(30)\n\nrandom_ts &lt;- tsibble(sample = 1:50, wn = rnorm(50), index = sample)\n\nautoplot(random_ts, wn)\n\n\n\n\n\n\n\n\nNow let’s calculate the autocorrelation coefficients, as we did above:\n\nACF(random_ts) |&gt; \n  autoplot()\n\n\n\n\n\n\n\nFigure 4.6\n\n\n\n\n\nThere is some autocorrelation: these data are not completely different from one another. This is okay: a broken clock is correct twice a day. Borrowing from frequentist statistics, we just need some threshold beyond which we are willing to say that these autocorrelations are sufficiently different from zero for us to consider them meaningful associations.\nFor example, let’s adopt the popular 5 percent threshold. We are willing to accept a five percent chance we say two values are meaningfully similar to each other when they are, in fact, not. These random values are Normally distributed. We know that 95 percent of the spikes in the ACF will lie within \\(\\pm \\frac{1.96}{\\sqrt{T}}\\) where \\(T\\) is the length of the time series.\nConveniently, autoplot() plots those boundaries for us (the dashed blue lines on Figure 4.5 and Figure 4.6). We can see that the first four lagged election years exceed this threshold. They are significantly different from zero: they are sufficiently similar to one another to suggest a meaningful relationship. Our white noise, on the other hand, never meets this threshold. Good! It’s just random values plucked from a Normal distribution.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#cycles",
    "href": "04_time_series.html#cycles",
    "title": "4  Finding Patterns Over Time",
    "section": "4.3 Cycles",
    "text": "4.3 Cycles\nA cycle occurs when the data exhibit rises and falls that are not of a fixed frequency. The fact that they are not of a fixed frequency is what distinguishes them from seasons.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#relationships-between-outcomes-and-time",
    "href": "04_time_series.html#relationships-between-outcomes-and-time",
    "title": "4  Finding Patterns Over Time",
    "section": "4.4 Relationships between outcomes and time",
    "text": "4.4 Relationships between outcomes and time",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#decomposing-time-series",
    "href": "04_time_series.html#decomposing-time-series",
    "title": "4  Finding Patterns Over Time",
    "section": "4.3 Decomposing time series",
    "text": "4.3 Decomposing time series\nWe have identified both a trend and seasonality in US general election voter turnout rates. How can we isolate those components? In other words, how can we extract the overall trend and identify the seasonal pattern in our data?\nWe can decompose a time series into three parts: its trend-cycle, seasonal, and remainder components. I will discuss how we do this shortly. But first, it is helpful to see the end result. Here are those three components of the voter turnout data:\n\ndcmp &lt;-  us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  model(stl = STL(vep_turnout_rate ~ season(period = \"4 years\")))\n\ncomponents(dcmp)\n\n# A dable: 13 x 8 [2Y]\n# Key:     state, .model [1]\n# :        vep_turnout_rate = trend + `season_4 years` + remainder\n   state         .model  year vep_turnout_rate trend `season_4 years` remainder\n   &lt;chr&gt;         &lt;chr&gt;  &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 United States stl     1998             39.3  47.4            -9.25    1.20  \n 2 United States stl     2000             55.3  48.2             9.26   -2.17  \n 3 United States stl     2002             40.5  49.2            -9.28    0.551 \n 4 United States stl     2004             60.9  50.8             9.29    0.768 \n 5 United States stl     2006             41.4  51.6            -9.30   -0.865 \n 6 United States stl     2008             62.2  51.5             9.32    1.34  \n 7 United States stl     2010             41.0  50.7            -9.34   -0.397 \n 8 United States stl     2012             58.6  48.6             9.37    0.592 \n 9 United States stl     2014             36.6  48.3            -9.39   -2.26  \n10 United States stl     2016             60.1  51.9             9.41   -1.16  \n11 United States stl     2018             50.0  56.1            -9.41    3.33  \n12 United States stl     2020             66.0  56.5             9.41    0.0952\n13 United States stl     2022             46.1  56.2            -9.41   -0.661 \n# ℹ 1 more variable: season_adjust &lt;dbl&gt;\n\n\nThe output provides the observed voter turnout rate (vep_turnout_rate) and then the three component parts (trend, season_4_ years, and remainder).\nThe trend component captures the broad pattern found within the series. It ignores any seasonal or random fluctuations. As Figure 4.10 shows, turnout at general elections is increasing over time. There is a slight dip in turnout in 2012 and 2014 (Obama’s second term, and the mid-term election that followed). This dip is much clearer when we strip the seasonality and random noise from the overall trend.\n\n\n\n\n\n\n\n\nFigure 4.10\n\n\n\n\n\nWe can look at all three components, and the observed turnout rates, in Figure 4.11. The seasonal component captures the extent to which voter turnout changes between mid-term and presidential election years. Interestingly, this appears to be consistent across our data: the extent to which a smaller proportion of people turnout to vote in mid-term elections compared to presidential ones has not changed since the late 1990s. Again, this is difficult to see when we don’t remove the (positive) trend from the data.\nThe remainder captures whatever variation exists in our data that are not accounted for by the trend and seasonal fluctuations.\n\n\n\n\n\n\n\n\nFigure 4.11\n\n\n\n\n\nThis is an additive decomposition, so you can get the observed turnout rate in any given election year by simply adding these three components together. This is appropriate because the magnitude of the seasonal fluctuations has not changed over time.\nAlternatively, we can calculate a multiplicative decomposition, in which the observed values are the product of the trend, seasonal, and remainder components. This method is best used when the seasonal component changes over time. For example, if the difference between turnouts in mid-term and presidential elections increased or decreased over time.\n\n4.3.1 Calculating the components of your time series\nThere are many different ways to decompose your time series. Here, we will focus on STL, which stands for Seasonal and Trend decomposition using LOESS. LOESS is a method for estimating non-linear relationships. Details of how STL (and LOESS) is calculated can be found in Cleveland, Cleveland, and Terpenning (1990).\nYou need to make two important decisions when using STL: the trend-cycle window and the seasonal window. These control how rapidly the trend-cycle and seasonal components can change, with smaller values allowing for more rapid changes.\nThe trend-cycle window is the number of consecutive observations you want to use to estimate the trend-cycle. It must be an odd number. A larger window results in a smoother trend-cycle line. Therefore, your model is less responsive to short-term fluctuations. A very large window can lead to oversmoothing, where some genuine cyclical variation is mistakenly pushed into the remainder component.\nA smaller window uses a smaller number of observations. This results in a more flexible or wiggly trend-cycle line, allowing it to closely follow rapid rises and falls in the data. A very small window can lead to overfitting, where the trend-cycle captures too much of the irregular or seasonal variation.\nIn general, you should use a number larger than the seasonal period of the data. For example, our seasonal pattern in US general election turnout rates runs over four years. Our trend cycle window should, therefore, be larger than four. Choosing the right window is a trade-off between capturing the true long-term movement and being overly sensitive to short-term noise.\nTo illustrate, Figure 4.12 shows the STL calculated with two different trend-cycle windows: a short one of seven, and a long one of 21. The longer window completely misses the dip during Obama’s second term and the subsequent mid-term election. (The dip is relegated to the remainder component.)\nWhich one should you use? Which ever one you think better represents the time series. We will discuss formal methods for comparing models later in the course, but your gut feeling (informed by your knowledge of the thing you are trying to model) is a wonderful asset. Trust it. For what it’s worth, I would pick the seven-year window.\n\n\n\n\n\n\n\n\nFigure 4.12\n\n\n\n\n\nThe seasonal window directly controls the rate at which the seasonal pattern is allowed to change over the length of the time series. It must also always be an odd number. A smaller window is more flexible. It allows the seasonal pattern to change more quickly over time. This is useful if you believe the seasonality is evolving or adapting (e.g., people’s holiday shopping habits are shifting). A larger window is less flexible or smoother. The seasonal pattern is held more constant over time. This is used if you believe the underlying seasonality is very stable. You can also set the seasonal window to be periodic or infinite. This forces the pattern to be completely fixed. The seasonal pattern is identical across all periods.\nFigure 4.13 compares a short (5 year), long (11 year), and periodic (fixed) window for US voter turnout. They are all very similar because the difference between voter turnout in presidential and mid-term elections has not changed all that much across these two-and-a-half decades of data.\n\n\n\n\n\n\n\n\nFigure 4.13\n\n\n\n\n\n\n\n4.3.2 Seasonally-adjusted data\nIf you do not care about the variation due to seasonality, you should remove it from your model of the relationship between time and our outcome of interest. This leaves you with the trend and remainder components. When we do this, we call the data “seasonally-adjusted”.\nYou should use seasonally-adjusted time series data to analyze underlying trends and compare movements between different time periods, as it removes the predictable, repeating patterns (like holiday shopping or weather effects) that naturally occur within a year. This allows you to see the “true” non-seasonal changes. It is useful for understanding short-term fluctuations beyond the usual patterns.\nHowever, if you want to find turning points in a series, and interpret any changes in direction, then you should use the trend-cycle component (as shown in Figure 4.10 for US voter turnouts) rather than the seasonally-adjusted data. The remainder component can distract from this analysis.\n\n\n\n\nCleveland, Robert B., William S. Cleveland, and Irma Terpenning. 1990. “STL: a seasonal-trend decomposition procedure based on loess.” Journal of official statistics 6 (1): 333.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#plotting-your-time-series-data",
    "href": "03_time_series_r.html#plotting-your-time-series-data",
    "title": "3  The Toolkit: R for Time Series",
    "section": "3.6 Plotting your time series data",
    "text": "3.6 Plotting your time series data\nPatterns in our data are often most easily detected when we visualize them. The simplest plot to start with is a time series plot. The ggtime R package provides a series of functions that make visualizing time series data simple.\nFor example, Figure 4.1 shows Mr Trump’s approval ratings across his current term.\n\nautoplot(trump_approval_ts) + \n  theme_minimal() + \n  labs(x = \"Date\",\n       y = \"Approval rating (%)\",\n       caption = \"Data source: The Economist/YouGov\") + \n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\nFigure 3.4: Mr Trump’s approval ratings since entering his second term in office.\n\n\n\n\n\nWe can see that Mr Trump’s popularity is declining. In fact, he has not yet enjoyed more than 50 percent of the US voting public’s approval.\n\n3.6.1 Plotting grouped data\nWe can also plot grouped data to more easily make comparisons between them. For example, Figure 3.5 plots each of the 18 AFL teams’ score percentages across the 2024 season. Some teams, including long-suffering North Melbourne, never managed to score more points than they conceded. Other teams, including the Sydney Swans, managed to never dip below 100 percent.\n\nautoplot(afl_ladder_ts, percentage) + \n  geom_hline(yintercept = 1, linetype = \"dashed\") +\n  theme_minimal() + \n  labs(x = \"Round\",\n       y = \"Scoring percentage\",\n       caption = \"Data source: AFL Tables\") + \n  scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\nFigure 3.5: AFL teams’ score percentage across the 2024 regular season.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#trends",
    "href": "04_time_series.html#trends",
    "title": "4  Finding Patterns Over Time",
    "section": "",
    "text": "Note\n\n\n\nA cycle occurs when the data exhibit rises and falls that are not of a fixed frequency. The fact that they are not of a fixed frequency is what distinguishes them from seasons.\n\n\n\n\n\n\n\n4.1.1 Relationships between values and time\nWe can more formally identify seasons by looking at the relationship between our values and time itself. A lag plot shows each value plotted against its previous value, lagged by varying time periods. The value is plotted on the y-axis and its corresponding lagged value is plotted on the x-axis.\nFor example, Figure 4.6 is a lag plot of turnout rates to US general elections. The first plot, titled lag 1, plots each election’s turnout rate against the turnout rate of the previous election. So the turnout rate for the 2022 election is plotted (on the y-axis) against the turnout rate for the 2020 election (x-axis). The second plot, titled lag 2, plots each election’s turnout rate against the rate of two elections ago. The turnout rate for the 2022 election is plotted against the turnout rate for the 2018 election.\n\nus_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  gg_lag(vep_turnout_rate, geom = \"point\") + \n  theme_minimal() + \n  labs(x = \"Turnout rate lagged (%)\",\n       y = \"Turnout rate (%)\",\n       caption = \"Data source: University of Florida Election Lab\")\n\n\n\n\n\n\n\nFigure 4.6: Lag plot of US general election turnout rates from 1998 to 2022.\n\n\n\n\n\nOdd numbered lags are, therefore, plotting turnout rates for mid-term and presidential elections against each other (for example, the 2022 mid-term election is plotted against the 2020 presidential election in lag 1). We tend to see two clusters of dots sitting in opposite corners of those graphs (lag 1, 3, 5, 7, and 9). These values are strongly negatively correlated.\nEven numbered lags are plotting like-for-like elections: mid-terms against mid-terms and presidentials against presidentials. We see a strong positive correlation in these plots (lag 2, 4, 6, and 8). The dots are scattered along the horizontal dashed line that represents equal values (a dot would sit on that line if the turnout rates of those two elections were the same).\nStrong correlations between values and their lagged counterparts at regular intervals are evidence of seasonality. We can calculate these correlations using feasts::ACF(). They are called autocorrelations because we are looking for the relationships lurking within the variable itself.\nLet’s look at autocorrelations for up to eight lagged election years:\n\nus_turnout_autocor &lt;- us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  ACF(var = vep_turnout_rate, lag_max = 8)\n\nus_turnout_autocor\n\n# A tsibble: 8 x 3 [2Y]\n# Key:       state [1]\n  state              lag    acf\n  &lt;chr&gt;         &lt;cf_lag&gt;  &lt;dbl&gt;\n1 United States       2Y -0.722\n2 United States       4Y  0.723\n3 United States       6Y -0.756\n4 United States       8Y  0.601\n5 United States      10Y -0.531\n6 United States      12Y  0.479\n7 United States      14Y -0.354\n8 United States      16Y  0.319\n\n\nAs usual, these data are much easier to digest visually. Let’s plot those autocorrelations:\n\nautoplot(us_turnout_autocor)\n\n\n\n\n\n\n\nFigure 4.7\n\n\n\n\n\nWe have formalized our intuition derived from the lag plots above: there is clear seasonality in our data. Voter turnout rates for mid-term and presidential elections are different (mid-term elections tend to be attended by fewer people). They are negatively autocorrelated (hence those lines shooting below 0). Turnout rates for like-elections (mid-term and mid-term, or presidential and presidential) are similar, or positively autocorrelated (hence the lines shoot up from 0).\nWe learn something else from these autocorrelations. Presidential (mid-term) elections that are closer in time to each other have more similar turnout rates. For example, the turnout rates for the 2022 and 2018 mid-term elections are more similar than those of the 2022 and 2002 elections. How do I know this? Well, the autocorrelation coefficient for smaller lags (for example, 1 and 3) are larger than the coefficient of larger lags (for example, 5 and 7). This indicates a trend in our data. Looking back at Figure 4.4, we can see that turnout rates have generally increased over time: a greater proportion of eligible voters tend to vote in more recent elections than they did in the late 90s and early 2000s.\n\n\n4.1.2 White noise\nSure, turnout rates in like elections look alike, but are they really that similar. How confident can we be that they are sufficiently similar to each other?\nFor example, I can make up some data that are genuinely random and still find some patterns within them that might suggest a trend, cycle, or even seasonality. I use rnorm() to randomly sample from a Normal distribution. These data points do not relate to one another. I should find no meaningful patterns within them.\n\nset.seed(30)\n\nrandom_ts &lt;- tsibble(sample = 1:50, wn = rnorm(50), index = sample)\n\nautoplot(random_ts, wn)\n\n\n\n\n\n\n\n\nNow let’s calculate the autocorrelation coefficients, as we did above:\n\nACF(random_ts) |&gt; \n  autoplot()\n\n\n\n\n\n\n\nFigure 4.8\n\n\n\n\n\nThere is some autocorrelation: these data are not completely different from one another. This is okay: a broken clock is correct twice a day. Borrowing from frequentist statistics, we just need some threshold beyond which we are willing to say that these autocorrelations are sufficiently different from zero for us to consider them meaningful associations.\nFor example, let’s adopt the popular 5 percent threshold. We are willing to accept a five percent chance we say two values are meaningfully similar to each other when they are, in fact, not. These random values are Normally distributed. We know that 95 percent of the spikes in the ACF will lie within \\(\\pm \\frac{1.96}{\\sqrt{T}}\\) where \\(T\\) is the length of the time series.\nConveniently, autoplot() plots those boundaries for us (the dashed blue lines on Figure 4.7 and Figure 4.8). We can see that the first four lagged election years exceed this threshold. They are significantly different from zero: they are sufficiently similar to one another to suggest a meaningful relationship. Our white noise, on the other hand, never meets this threshold. Good! It’s just random values plucked from a Normal distribution.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#seasons",
    "href": "04_time_series.html#seasons",
    "title": "4  Finding Patterns Over Time",
    "section": "4.2 Seasons",
    "text": "4.2 Seasons\nSome of those fluctuations away from our trend are important. This is especially the case when they occur repeatedly, either at regular intervals or in cycles. A seasonal pattern occurs when a time series exhibits patterns at regular intervals. Seasonality is always of a fixed and known period.\n\n\n\n\n\n\nNote\n\n\n\nA cycle occurs when the data exhibit rises and falls that are not of a fixed frequency. The fact that they are not of a fixed frequency is what distinguishes them from seasons.\n\n\nFor example, voter turnout rates are always higher than they were two years previously, as shown in Figure 4.4. This is because mid-term general elections consistently get a lower turnout than presidential general election years.\n\n\n\n\n\n\n\n\nFigure 4.4: Eligible voter turnout rates at the federal level to US General Elections from 1998 to 2022.\n\n\n\n\n\nAs shown in Figure 4.5, we can see this seasonal pattern generally holds across the 50 US states and the District of Columbia.\n\n\n\n\n\n\n\n\nFigure 4.5: Eligible voter turnout rates in all 50 US states and the District of Columbia to US General Elections from 1998 to 2022.\n\n\n\n\n\n\n4.2.1 Relationships between values and time\nWe can more formally identify seasons by looking at the relationship between our values and time itself. A lag plot shows each value plotted against its previous value, lagged by varying time periods. The value is plotted on the y-axis and its corresponding lagged value is plotted on the x-axis.\nFor example, Figure 4.6 is a lag plot of turnout rates to US general elections. The first plot, titled lag 1, plots each election’s turnout rate against the turnout rate of the previous election. So the turnout rate for the 2022 election is plotted (on the y-axis) against the turnout rate for the 2020 election (x-axis). The second plot, titled lag 2, plots each election’s turnout rate against the rate of two elections ago. The turnout rate for the 2022 election is plotted against the turnout rate for the 2018 election.\n\nus_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  gg_lag(vep_turnout_rate, geom = \"point\") + \n  theme_minimal() + \n  labs(x = \"Turnout rate lagged (%)\",\n       y = \"Turnout rate (%)\",\n       caption = \"Data source: University of Florida Election Lab\")\n\n\n\n\n\n\n\nFigure 4.6: Lag plot of US general election turnout rates from 1998 to 2022.\n\n\n\n\n\nOdd numbered lags are, therefore, plotting turnout rates for mid-term and presidential elections against each other (for example, the 2022 mid-term election is plotted against the 2020 presidential election in lag 1). We tend to see two clusters of dots sitting in opposite corners of those graphs (lag 1, 3, 5, 7, and 9). These values are strongly negatively correlated.\nEven numbered lags are plotting like-for-like elections: mid-terms against mid-terms and presidentials against presidentials. We see a strong positive correlation in these plots (lag 2, 4, 6, and 8). The dots are scattered along the horizontal dashed line that represents equal values (a dot would sit on that line if the turnout rates of those two elections were the same).\nStrong correlations between values and their lagged counterparts at regular intervals are evidence of seasonality. We can calculate these correlations using feasts::ACF(). They are called autocorrelations because we are looking for the relationships lurking within the variable itself.\nLet’s look at autocorrelations for up to eight lagged election years:\n\nus_turnout_autocor &lt;- us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  ACF(var = vep_turnout_rate, lag_max = 8)\n\nus_turnout_autocor\n\n# A tsibble: 8 x 3 [2Y]\n# Key:       state [1]\n  state              lag    acf\n  &lt;chr&gt;         &lt;cf_lag&gt;  &lt;dbl&gt;\n1 United States       2Y -0.722\n2 United States       4Y  0.723\n3 United States       6Y -0.756\n4 United States       8Y  0.601\n5 United States      10Y -0.531\n6 United States      12Y  0.479\n7 United States      14Y -0.354\n8 United States      16Y  0.319\n\n\nAs usual, these data are much easier to digest visually. Let’s plot those autocorrelations:\n\nautoplot(us_turnout_autocor)\n\n\n\n\n\n\n\nFigure 4.7\n\n\n\n\n\nWe have formalized our intuition derived from the lag plots above: there is clear seasonality in our data. Voter turnout rates for mid-term and presidential elections are different (mid-term elections tend to be attended by fewer people). They are negatively autocorrelated (hence those lines shooting below 0). Turnout rates for like-elections (mid-term and mid-term, or presidential and presidential) are similar, or positively autocorrelated (hence the lines shoot up from 0).\nWe learn something else from these autocorrelations. Presidential (mid-term) elections that are closer in time to each other have more similar turnout rates. For example, the turnout rates for the 2022 and 2018 mid-term elections are more similar than those of the 2022 and 2002 elections. How do I know this? Well, the autocorrelation coefficient for smaller lags (for example, 1 and 3) are larger than the coefficient of larger lags (for example, 5 and 7). This indicates a trend in our data. Looking back at Figure 4.4, we can see that turnout rates have generally increased over time: a greater proportion of eligible voters tend to vote in more recent elections than they did in the late 90s and early 2000s.\n\n\n4.2.2 White noise\nSure, turnout rates in like elections look alike, but are they really that similar. How confident can we be that they are sufficiently similar to each other?\nFor example, I can make up some data that are genuinely random and still find some patterns within them that might suggest a trend, cycle, or even seasonality. I use rnorm() to randomly sample from a Normal distribution. These data points do not relate to one another. I should find no meaningful patterns within them.\n\nset.seed(30)\n\nrandom_ts &lt;- tsibble(sample = 1:50, wn = rnorm(50), index = sample)\n\nautoplot(random_ts, wn)\n\n\n\n\n\n\n\n\nNow let’s calculate the autocorrelation coefficients, as we did above:\n\nACF(random_ts) |&gt; \n  autoplot()\n\n\n\n\n\n\n\nFigure 4.8\n\n\n\n\n\nThere is some autocorrelation: these data are not completely different from one another. This is okay: a broken clock is correct twice a day. Borrowing from frequentist statistics, we just need some threshold beyond which we are willing to say that these autocorrelations are sufficiently different from zero for us to consider them meaningful associations.\nFor example, let’s adopt the popular 5 percent threshold. We are willing to accept a five percent chance we say two values are meaningfully similar to each other when they are, in fact, not. These random values are Normally distributed. We know that 95 percent of the spikes in the ACF will lie within \\(\\pm \\frac{1.96}{\\sqrt{T}}\\) where \\(T\\) is the length of the time series.\nConveniently, autoplot() plots those boundaries for us (the dashed blue lines on Figure 4.7 and Figure 4.8). We can see that the first four lagged election years exceed this threshold. They are significantly different from zero: they are sufficiently similar to one another to suggest a meaningful relationship. Our white noise, on the other hand, never meets this threshold. Good! It’s just random values plucked from a Normal distribution.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#seasons-and-cycles",
    "href": "04_time_series.html#seasons-and-cycles",
    "title": "4  Finding Patterns Over Time",
    "section": "4.2 Seasons and cycles",
    "text": "4.2 Seasons and cycles\nSome of those fluctuations away from our trend are important. This is especially the case when they occur repeatedly. A seasonal pattern occurs when a time series deviates from its trend with some pattern and at regular intervals. Seasonality is always of a fixed and known period. On the other hand, a cycle occurs when a time series rises and falls in a regular pattern away from its trend, but not at a fixed frequency.\nLet’s focus on a seasonal pattern in some political data. Voter turnout rates in US general elections are always higher than they were two years previously, as shown in Figure 4.4. This is because mid-term general elections consistently get a lower turnout than presidential general elections.\n\n\n\n\n\n\n\n\nFigure 4.4: Eligible voter turnout rates at the federal level to US General Elections from 1998 to 2022.\n\n\n\n\n\nAs shown in Figure 4.5, we can see this saw-tooth, seasonal pattern generally holds across the 50 US states and the District of Columbia.\n\n\n\n\n\n\n\n\nFigure 4.5: Eligible voter turnout rates in all 50 US states and the District of Columbia to US General Elections from 1998 to 2022.\n\n\n\n\n\nWhen trying to understand the relationship between voter turnout and time (for example, if we want to predict next election’s turnout rate), we should account for these patterns.\n\n4.2.1 Identifying the seasons\nWe can more formally identify whether our time series is seasonal than by eyeballing these patterns. These patterns are defined across time. So, we can look at how the value changes over time to identify that pattern. For example, we can identify the saw-tooth pattern in US voter turnout by comparing each value to its previous value. If those comparisons match their counterparts, we have evidence of a repeated pattern.\nThis is best understood through an illustration. To begin, let’s use a lag plot. This plots each value against its previous value, lagged by varying time periods. The value is plotted on the y-axis and its corresponding lagged value is plotted on the x-axis.\nFigure 4.6 is a lag plot of US general election turnout rates. The first plot, titled lag 1, plots each election’s turnout rate against the turnout rate of the previous election. So the turnout rate for the 2022 election is plotted (on the y-axis) against the turnout rate for the 2020 election (x-axis). The second plot, titled lag 2, plots each election’s turnout rate against the turnout rate of two elections ago. The turnout rate for the 2022 election is plotted against the turnout rate for the 2018 election.\n\nus_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  gg_lag(vep_turnout_rate, geom = \"point\") + \n  theme_minimal() + \n  labs(x = \"Turnout rate lagged (%)\",\n       y = \"Turnout rate (%)\",\n       caption = \"Data source: University of Florida Election Lab\")\n\n\n\n\n\n\n\nFigure 4.6: Lag plot of US general election turnout rates from 1998 to 2022.\n\n\n\n\n\nIf the two election turnout rates are exactly the same, they will fall on the dashed grey line cutting diagonally through each plot. If the two election rates are very different from one another, they will cluster in the upper left hand or lower right hand corners of the plots.\nOdd numbered lags (1, 3, 5, 7, and 9) plot turnout rates for mid-term and presidential elections against each other (for example, the 2022 mid-term election is plotted against the 2020 presidential election in lag 1). We consistently see two clusters of dots sitting in opposite corners of those graphs. This means that their turnout rates tend to be very different from each other. More formally, these values are strongly negatively (auto)correlated.\nEven numbered lags (2, 4, 6, and 8) are plotting like-for-like elections: mid-terms against mid-terms and presidentials against presidentials. We see a strong positive (auto)correlation in these plots. The dots are scattered close to the horizontal dashed line that represents equal values.\nStrong correlations between values and their lagged counterparts at regular intervals are evidence of seasonality. (If these correlations occur at irregular intervals, this is evidence of cycles.) We can calculate these correlations using feasts::ACF(). They are called autocorrelations because we are looking for the relationships lurking within the variable itself.\nLet’s look at autocorrelation coefficients for up to eight lagged election years:\n\nus_turnout_autocor &lt;- us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  ACF(var = vep_turnout_rate, lag_max = 8)\n\nus_turnout_autocor\n\n# A tsibble: 8 x 3 [2Y]\n# Key:       state [1]\n  state              lag    acf\n  &lt;chr&gt;         &lt;cf_lag&gt;  &lt;dbl&gt;\n1 United States       2Y -0.722\n2 United States       4Y  0.723\n3 United States       6Y -0.756\n4 United States       8Y  0.601\n5 United States      10Y -0.531\n6 United States      12Y  0.479\n7 United States      14Y -0.354\n8 United States      16Y  0.319\n\n\nAs usual, these data are much easier to digest visually. Let’s plot those autocorrelation coefficients:\n\nautoplot(us_turnout_autocor)\n\n\n\n\n\n\n\nFigure 4.7\n\n\n\n\n\nFigure 4.7 shows the value of the autocorrelation as a spike emerging from the x-axis. A line descending below the x-axis indicates a negative correlation and, conversely, a line ascending above the x-axis indicates a positive one. Stronger correlations are shown by longer lines.\nVoter turnout rates for mid-term and presidential elections are different. This is shown by the negative autocorrelation at odd-numbered intervals. Turnout rates for like-elections (mid-term and mid-term, or presidential and presidential) are similar to each other, or positively autocorrelated. The clear pattern in these autocorrelations (negative, positive, negative, positive, etc.) is evidence of seasonality.\n\n\n4.2.2 White noise\nSure, turnout rates in like elections look alike, but are they really that similar. How confident can we be that they are sufficiently similar to each other to indicate a pattern? To answer this question, I will make up some data that are genuinely random. By design, there are no patterns (seasons or cycles) in these data.\nI use rbinom() to randomly sample from a binomial distribution. These data points do not relate to one another. I should find no meaningful patterns within them.\n\nset.seed(1234)\n\nrandom_ts &lt;- tsibble(sample = 1:50, value = rbinom(50, 50, prob = 0.5), \n                     index = sample)\n\nautoplot(random_ts, value)\n\n\n\n\n\n\n\n\nNow let’s calculate the autocorrelation coefficients, as we did above:\n\nACF(random_ts) |&gt; \n  autoplot()\n\n\n\n\n\n\n\nFigure 4.8\n\n\n\n\n\nThere is some autocorrelation: these data are not completely different from one another. This is normal, but we need some way of distinguishing this white noise from meaningful correlations. Borrowing from frequentist statistics, we need some threshold beyond which we are willing to say that these autocorrelation coefficients are sufficiently different from zero for us to consider them meaningful associations.\nAutocorrelation coefficients from an infinitely large random sample follow a Normal distribution centered at zero. Don’t take my word for it: Figure 4.9 shows the autocorrelations among a very large random sample1 from a binomial distribution2. They fall along that lovely bell-shaped curve.\n\nset.seed(1234)\n\nlarge_random_ts &lt;- tsibble(sample = 1:1e5, value = rbinom(1e5, size = 1e5, \n                                                          prob = 0.5), \n                           index = sample)\n\n\nlarge_random_acf &lt;- ACF(large_random_ts, lag_max = 1e5)\n\nggplot() + \n  geom_density(aes(x = large_random_acf$acf)) + \n  theme_minimal()\n\n\n\n\n\n\n\nFigure 4.9\n\n\n\n\n\nThis is very handy because we know what proportion of those infinite values fall at any point along a standard Normal distribution (centered at zero and with a standard deviation of one). For example, we know that 95 percent of these values fall between roughly 1.96 standard deviations above and below that center point.\nSo, if our values are random and there is no relationship between them, we will get autocorrelation coefficients between them that are Normally distributed with a center point of zero. Now, we can place any autocorrelation coefficient we do find in our data within this context. I can calculate how likely I was to get that coefficient or a more extreme one if my values are, in fact, just random.\nLook again at Figure 4.9. A lot of the coefficients from that completely random draw sit between -0.005 and 0.005. So, if I get a coefficient within that range it is very plausible that it resulted from a completely random sample. I don’t have enough evidence that the relationship is anything other than white noise. If; however, I get a coefficient of, say, 0.010 or higher, I’m starting to get a bit suspicious of the idea that the values are random. It is really unlikely that I would find a coefficient that big if they were.\nIn the sciences, we generally accept a five percent chance that we will incorrectly say that the value we found was so extreme that it provides us with good evidence our data are not random. This five percent threshold is commonly referred to as p = 0.05: you should remember it from any statistics courses you have taken.\nSo, we know that 95 percent of the autocorrelation coefficients that could plausibly result from random values fall 1.96 standard deviations away from a standardized Normal distribution. So if the coefficients we find in our data fall further from their center than 1.96 standard deviations above and below it, we have good evidence to reject the idea that these data are not autocorrelated. Gosh, that was a lot of double negatives. Frequestist statistics requires us to stretch our intuition a little far.\nTo locate our autocorrelation coefficient on this standard Normal distribution, we ask whether it lies outside of \\(\\pm \\frac{1.96}{\\sqrt{T}}\\), where \\(T\\) is the length of the time series. Conveniently, autoplot() plots those boundaries for us (the dashed blue lines on Figure 4.7 and Figure 4.8).\nFrom Figure 4.7, we can see that the first four lagged election years exceed this threshold. They are sufficiently different from zero. In other words, they are sufficiently similar to one another to suggest a meaningful relationship. Our white noise (Figure 4.8), on the other hand, never meets this threshold. Good! It’s just random values plucked from a binomial distribution.\nInterestingly, the degree to which turnout rates a similar to each other decrease over time. Elections that were more than four elections away from each other are too different from each other to suggest they are related. This hints at a trend. Looking back at Figure 4.4, it appears that the turnout rate for US elections is increasing. A greater proportion of eligible voters showed up in recent elections than in elections held in the late 1990s and early 2000s.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#decomposing-time-series-1",
    "href": "04_time_series.html#decomposing-time-series-1",
    "title": "4  Finding Patterns Over Time",
    "section": "4.4 Decomposing time series",
    "text": "4.4 Decomposing time series\nIt is often useful to decompose a time series into three parts: its trend-cycle, seasonal, and remainder components.\n\ndcmp &lt;-  us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  model(stl = STL(vep_turnout_rate ~ season(period = \"4 years\")))\n\ncomponents(dcmp)\n\n# A dable: 13 x 8 [2Y]\n# Key:     state, .model [1]\n# :        vep_turnout_rate = trend + `season_4 years` + remainder\n   state         .model  year vep_turnout_rate trend `season_4 years` remainder\n   &lt;chr&gt;         &lt;chr&gt;  &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 United States stl     1998             39.3  47.4            -9.25    1.20  \n 2 United States stl     2000             55.3  48.2             9.26   -2.17  \n 3 United States stl     2002             40.5  49.2            -9.28    0.551 \n 4 United States stl     2004             60.9  50.8             9.29    0.768 \n 5 United States stl     2006             41.4  51.6            -9.30   -0.865 \n 6 United States stl     2008             62.2  51.5             9.32    1.34  \n 7 United States stl     2010             41.0  50.7            -9.34   -0.397 \n 8 United States stl     2012             58.6  48.6             9.37    0.592 \n 9 United States stl     2014             36.6  48.3            -9.39   -2.26  \n10 United States stl     2016             60.1  51.9             9.41   -1.16  \n11 United States stl     2018             50.0  56.1            -9.41    3.33  \n12 United States stl     2020             66.0  56.5             9.41    0.0952\n13 United States stl     2022             46.1  56.2            -9.41   -0.661 \n# ℹ 1 more variable: season_adjust &lt;dbl&gt;\n\n\nThe output provides the observed voter turnout rate (vep_turnout_rate) and then the three component parts.\nThe trend component captures the general pattern found within the series. It ignores any seasonal or random fluctuations:\n\n\n\n\n\n\n\n\nFigure 4.9\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe seasonal component captures the extent to which voter turnout changes between mid-term and presidential election years. Interestingly, this appears consistent across our data: the extent to which a smaller proportion of people turnout to vote in mid-term elections compared to presidential ones has not changed since the late 1990s.\nThe remainder captures whatever variation exists in our data that are not accounted for by the general (in this case, positive) trend and seasonal fluctuations.\nThis is an additive decomposition, so you can get the observed turnout rate in any given election year by simply adding these three components together. This is appropriate because the magnitude of the seasonal fluctuations has not changed over time. Alternatively, we can calculate a multiplicative decomposition, in which the observed values are the product of the trend, seasonal, and remainder components. A multiplicative decomposition is best used when the seasonal component changes over time. For example, if the difference between turnouts in mid-term and presidential elections was increasing over time.\n\n4.4.1 Seasonally-adjusted data\nIf the variation due to seasonality is not of primary interest, we should remove it from our model of the relationship between time and our outcome of interest. When we do this, we call the data “seasonally-adjusted”.\n\n\n\n\n\n\n\n\n\nYou should use seasonally adjusted time series data to analyze underlying trends and compare movements between different time periods, as it removes the predictable, repeating patterns (like holiday shopping or weather effects) that naturally occur within a year. This allows you to see the “true” non-seasonal changes and is ideal for economic analysis, policy-making, and understanding short-term fluctuations beyond the usual yearly cycles.\nHowever, if the purpose is to look for turning points in a series, and interpret any changes in direction, then it is better to use the trend-cycle component (as shown in Figure 4.9) rather than the seasonally adjusted data. This seasonally adjusted data still include that remainder element.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series.html#footnotes",
    "href": "04_time_series.html#footnotes",
    "title": "4  Finding Patterns Over Time",
    "section": "",
    "text": "I use a sample of 100,000 for illustrative purposes. Sadly, I can’t take an infinitely large sample.↩︎\nAutocorrelation coefficients will be Normally distributed when drawn from a large sample of any distribution!↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series_decomposed.html",
    "href": "04_time_series_decomposed.html",
    "title": "4  Finding Patterns Over Time",
    "section": "",
    "text": "4.1 The Art of Decomposition\nAt its core, time series forecasting is about recognizing patterns. When we look at a time series—like a stock price, a monthly sales figure, or a political approval rating—what we see is often a messy, complicated line. Our goal in this chapter is to develop the skills to explore and formalize the relationship between our outcome of interest and time itself by breaking that messy line into three cleaner, more predictable components: the Trend, the Seasonality, and the Remainder.\nThis process is called Time Series Decomposition. It’s like taking apart a complex machine (the time series) into its simple, functional components. Once we understand how each component works in isolation, we can put them back together to make powerful predictions.\nThe decomposition model we rely on is generally expressed as:\nTrends\nLet’s take another look at Mr Trump’s approval rating over his current term in office, which is shown in Figure 4.1. If I asked you to summarize how his popularity was tracking, what would you say?\nFigure 4.1: Mr Trump’s approval ratings since entering his second term in office.\nIn general, his approval rating is decreasing. In fact, I can draw a straight line through these data to capture that downward trend, as I have done in Figure 4.2. A trend exists when there is a long-term increase or decrease in the data. We use the trend to describe the general pattern of our data, ignoring small or random fluctuations and noise.\nFigure 4.2: Mr Trump’s approval ratings since entering his second term in office.\nTrends do not need to be linear. For example, Figure 4.3 shows global Gross Domestic Product (GDP) from 1952 to 2007. In general, GDP is growing at an increasing rate. Therefore, its trend is positive and exponential.\nFigure 4.3: Global Gross Domestic Product from 1952 to 2007.\nTrends are useful summaries of the general relationship between your variable of interest and time. By stripping away fluctuations from this general pattern, we gain a better understanding of the broad thrust of our data. We will learn how to do this formally shortly.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series_decomposed.html#seasons-and-cycles",
    "href": "04_time_series_decomposed.html#seasons-and-cycles",
    "title": "4  Finding Patterns Over Time",
    "section": "4.2 Seasons and cycles",
    "text": "4.2 Seasons and cycles\nSome of those fluctuations away from our trend are important. This is especially the case when they occur repeatedly. A seasonal pattern occurs when a time series deviates from its trend with some pattern and at regular intervals. Seasonality is always of a fixed and known period. On the other hand, a cycle occurs when a time series rises and falls in a regular pattern away from its trend, but not at a fixed frequency.\nLet’s focus on a seasonal pattern in some political data. Voter turnout rates in US general elections are always higher than they were two years previously, as shown in Figure 4.4. This is because mid-term general elections consistently get a lower turnout than presidential general elections.\n\n\n\n\n\n\n\n\nFigure 4.4: Eligible voter turnout rates at the federal level to US General Elections from 1998 to 2022.\n\n\n\n\n\nAs shown in Figure 4.5, we can see this saw-tooth, seasonal pattern generally holds across the 50 US states and the District of Columbia.\n\n\n\n\n\n\n\n\nFigure 4.5: Eligible voter turnout rates in all 50 US states and the District of Columbia to US General Elections from 1998 to 2022.\n\n\n\n\n\nWhen trying to understand the relationship between voter turnout and time (for example, if we want to predict next election’s turnout rate), we should account for these patterns.\n\n4.2.1 Identifying the seasons\nWe can more formally identify whether our time series is seasonal than by eyeballing these patterns. These patterns are defined across time. So, we can look at how the value changes over time to identify that pattern. For example, we can identify the saw-tooth pattern in US voter turnout by comparing each value to its previous value. If those comparisons match their counterparts, we have evidence of a repeated pattern.\nThis is best understood through an illustration. To begin, let’s use a lag plot. This plots each value against its previous value, lagged by varying time periods. The value is plotted on the y-axis and its corresponding lagged value is plotted on the x-axis.\nFigure 4.6 is a lag plot of US general election turnout rates. The first plot, titled lag 1, plots each election’s turnout rate against the turnout rate of the previous election. So the turnout rate for the 2022 election is plotted (on the y-axis) against the turnout rate for the 2020 election (x-axis). The second plot, titled lag 2, plots each election’s turnout rate against the turnout rate of two elections ago. The turnout rate for the 2022 election is plotted against the turnout rate for the 2018 election.\n\nus_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  gg_lag(vep_turnout_rate, geom = \"point\") + \n  theme_minimal() + \n  labs(x = \"Turnout rate lagged (%)\",\n       y = \"Turnout rate (%)\",\n       caption = \"Data source: University of Florida Election Lab\")\n\n\n\n\n\n\n\nFigure 4.6: Lag plot of US general election turnout rates from 1998 to 2022.\n\n\n\n\n\nIf the two election turnout rates are exactly the same, they will fall on the dashed grey line cutting diagonally through each plot. If the two election rates are very different from one another, they will cluster in the upper left hand or lower right hand corners of the plots.\nOdd numbered lags (1, 3, 5, 7, and 9) plot turnout rates for mid-term and presidential elections against each other (for example, the 2022 mid-term election is plotted against the 2020 presidential election in lag 1). We consistently see two clusters of dots sitting in opposite corners of those graphs. This means that their turnout rates tend to be very different from each other. More formally, these values are strongly negatively (auto)correlated.\nEven numbered lags (2, 4, 6, and 8) are plotting like-for-like elections: mid-terms against mid-terms and presidentials against presidentials. We see a strong positive (auto)correlation in these plots. The dots are scattered close to the horizontal dashed line that represents equal values.\nStrong correlations between values and their lagged counterparts at regular intervals are evidence of seasonality. (If these correlations occur at irregular intervals, this is evidence of cycles.) We can calculate these correlations using feasts::ACF(). They are called autocorrelations because we are looking for the relationships lurking within the variable itself.\nLet’s look at autocorrelation coefficients for up to eight lagged election years:\n\nus_turnout_autocor &lt;- us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  ACF(var = vep_turnout_rate, lag_max = 8)\n\nus_turnout_autocor\n\n# A tsibble: 8 x 3 [2Y]\n# Key:       state [1]\n  state              lag    acf\n  &lt;chr&gt;         &lt;cf_lag&gt;  &lt;dbl&gt;\n1 United States       2Y -0.722\n2 United States       4Y  0.723\n3 United States       6Y -0.756\n4 United States       8Y  0.601\n5 United States      10Y -0.531\n6 United States      12Y  0.479\n7 United States      14Y -0.354\n8 United States      16Y  0.319\n\n\nAs usual, these data are much easier to digest visually. Let’s plot those autocorrelation coefficients:\n\nautoplot(us_turnout_autocor)\n\n\n\n\n\n\n\nFigure 4.7\n\n\n\n\n\nFigure 4.7 shows the value of the autocorrelation as a spike emerging from the x-axis. A line descending below the x-axis indicates a negative correlation and, conversely, a line ascending above the x-axis indicates a positive one. Stronger correlations are shown by longer lines.\nVoter turnout rates for mid-term and presidential elections are different. This is shown by the negative autocorrelation at odd-numbered intervals. Turnout rates for like-elections (mid-term and mid-term, or presidential and presidential) are similar to each other, or positively autocorrelated. The clear pattern in these autocorrelations (negative, positive, negative, positive, etc.) is evidence of seasonality.\n\n\n4.2.2 White noise\nSure, turnout rates in like elections look alike, but are they really that similar. How confident can we be that they are sufficiently similar to each other to indicate a pattern? To answer this question, I will make up some data that are genuinely random. By design, there are no patterns (seasons or cycles) in these data.\nI use rbinom() to randomly sample from a binomial distribution. These data points do not relate to one another. I should find no meaningful patterns within them.\n\nset.seed(1234)\n\nrandom_ts &lt;- tsibble(sample = 1:50, value = rbinom(50, 50, prob = 0.5), \n                     index = sample)\n\nautoplot(random_ts, value)\n\n\n\n\n\n\n\n\nNow let’s calculate the autocorrelation coefficients, as we did above:\n\nACF(random_ts) |&gt; \n  autoplot()\n\n\n\n\n\n\n\nFigure 4.8\n\n\n\n\n\nThere is some autocorrelation: these data are not completely different from one another. This is normal, but we need some way of distinguishing this white noise from meaningful correlations. Borrowing from frequentist statistics, we need some threshold beyond which we are willing to say that these autocorrelation coefficients are sufficiently different from zero for us to consider them meaningful associations.\nAutocorrelation coefficients from an infinitely large random sample follow a Normal distribution centered at zero. Don’t take my word for it: Figure 4.9 shows the autocorrelations among a very large random sample1 from a binomial distribution2. They fall along that lovely bell-shaped curve.\n\nset.seed(1234)\n\nlarge_random_ts &lt;- tsibble(sample = 1:1e5, value = rbinom(1e5, size = 1e5, \n                                                          prob = 0.5), \n                           index = sample)\n\n\nlarge_random_acf &lt;- ACF(large_random_ts, lag_max = 1e5)\n\nggplot() + \n  geom_density(aes(x = large_random_acf$acf)) + \n  theme_minimal()\n\n\n\n\n\n\n\nFigure 4.9\n\n\n\n\n\nThis is very handy because we know what proportion of those infinite values fall at any point along a standard Normal distribution (centered at zero and with a standard deviation of one). For example, we know that 95 percent of these values fall between roughly 1.96 standard deviations above and below that center point.\nSo, if our values are random and there is no relationship between them, we will get autocorrelation coefficients between them that are Normally distributed with a center point of zero. Now, we can place any autocorrelation coefficient we do find in our data within this context. I can calculate how likely I was to get that coefficient or a more extreme one if my values are, in fact, just random.\nLook again at Figure 4.9. A lot of the coefficients from that completely random draw sit between -0.005 and 0.005. So, if I get a coefficient within that range it is very plausible that it resulted from a completely random sample. I don’t have enough evidence that the relationship is anything other than white noise. If; however, I get a coefficient of, say, 0.010 or higher, I’m starting to get a bit suspicious of the idea that the values are random. It is really unlikely that I would find a coefficient that big if they were.\nIn the sciences, we generally accept a five percent chance that we will incorrectly say that the value we found was so extreme that it provides us with good evidence our data are not random. This five percent threshold is commonly referred to as p = 0.05: you should remember it from any statistics courses you have taken.\nSo, we know that 95 percent of the autocorrelation coefficients that could plausibly result from random values fall 1.96 standard deviations away from a standardized Normal distribution. So if the coefficients we find in our data fall further from their center than 1.96 standard deviations above and below it, we have good evidence to reject the idea that these data are not autocorrelated. Gosh, that was a lot of double negatives. Frequestist statistics requires us to stretch our intuition a little far.\nTo locate our autocorrelation coefficient on this standard Normal distribution, we ask whether it lies outside of \\(\\pm \\frac{1.96}{\\sqrt{T}}\\), where \\(T\\) is the length of the time series. Conveniently, autoplot() plots those boundaries for us (the dashed blue lines on Figure 4.7 and Figure 4.8).\nFrom Figure 4.7, we can see that the first four lagged election years exceed this threshold. They are sufficiently different from zero. In other words, they are sufficiently similar to one another to suggest a meaningful relationship. Our white noise (Figure 4.8), on the other hand, never meets this threshold. Good! It’s just random values plucked from a binomial distribution.\nInterestingly, the degree to which turnout rates a similar to each other decrease over time. Elections that were more than four elections away from each other are too different from each other to suggest they are related. This hints at a trend. Looking back at Figure 4.4, it appears that the turnout rate for US elections is increasing. A greater proportion of eligible voters showed up in recent elections than in elections held in the late 1990s and early 2000s.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series_decomposed.html#decomposing-time-series",
    "href": "04_time_series_decomposed.html#decomposing-time-series",
    "title": "4  Finding Patterns Over Time",
    "section": "4.3 Decomposing time series",
    "text": "4.3 Decomposing time series\nWe have identified both a trend and seasonality in US general election voter turnout rates. How can we isolate those components? In other words, how can we extract the overall trend and identify the seasonal pattern in our data?\nWe can decompose a time series into three parts: its trend-cycle, seasonal, and remainder components. I will discuss how we do this shortly. But first, it is helpful to see the end result. Here are those three components of the voter turnout data:\n\ndcmp &lt;-  us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  model(stl = STL(vep_turnout_rate ~ season(period = \"4 years\")))\n\ncomponents(dcmp)\n\n# A dable: 13 x 8 [2Y]\n# Key:     state, .model [1]\n# :        vep_turnout_rate = trend + `season_4 years` + remainder\n   state         .model  year vep_turnout_rate trend `season_4 years` remainder\n   &lt;chr&gt;         &lt;chr&gt;  &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n 1 United States stl     1998             39.3  47.4            -9.25    1.20  \n 2 United States stl     2000             55.3  48.2             9.26   -2.17  \n 3 United States stl     2002             40.5  49.2            -9.28    0.551 \n 4 United States stl     2004             60.9  50.8             9.29    0.768 \n 5 United States stl     2006             41.4  51.6            -9.30   -0.865 \n 6 United States stl     2008             62.2  51.5             9.32    1.34  \n 7 United States stl     2010             41.0  50.7            -9.34   -0.397 \n 8 United States stl     2012             58.6  48.6             9.37    0.592 \n 9 United States stl     2014             36.6  48.3            -9.39   -2.26  \n10 United States stl     2016             60.1  51.9             9.41   -1.16  \n11 United States stl     2018             50.0  56.1            -9.41    3.33  \n12 United States stl     2020             66.0  56.5             9.41    0.0952\n13 United States stl     2022             46.1  56.2            -9.41   -0.661 \n# ℹ 1 more variable: season_adjust &lt;dbl&gt;\n\n\nThe output provides the observed voter turnout rate (vep_turnout_rate) and then the three component parts (trend, season_4_ years, and remainder).\nThe trend component captures the broad pattern found within the series. It ignores any seasonal or random fluctuations. As Figure 4.10 shows, turnout at general elections is increasing over time. There is a slight dip in turnout in 2012 and 2014 (Obama’s second term, and the mid-term election that followed). This dip is much clearer when we strip the seasonality and random noise from the overall trend.\n\n\n\n\n\n\n\n\nFigure 4.10\n\n\n\n\n\nWe can look at all three components, and the observed turnout rates, in Figure 4.11. The seasonal component captures the extent to which voter turnout changes between mid-term and presidential election years. Interestingly, this appears to be consistent across our data: the extent to which a smaller proportion of people turnout to vote in mid-term elections compared to presidential ones has not changed since the late 1990s. Again, this is difficult to see when we don’t remove the (positive) trend from the data.\nThe remainder captures whatever variation exists in our data that are not accounted for by the trend and seasonal fluctuations.\n\n\n\n\n\n\n\n\nFigure 4.11\n\n\n\n\n\nThis is an additive decomposition, so you can get the observed turnout rate in any given election year by simply adding these three components together. This is appropriate because the magnitude of the seasonal fluctuations has not changed over time.\nAlternatively, we can calculate a multiplicative decomposition, in which the observed values are the product of the trend, seasonal, and remainder components. This method is best used when the seasonal component changes over time. For example, if the difference between turnouts in mid-term and presidential elections increased or decreased over time.\n\n4.3.1 Calculating the components of your time series\nThere are many different ways to decompose your time series. Here, we will focus on STL, which stands for Seasonal and Trend decomposition using LOESS. LOESS is a method for estimating non-linear relationships. Details of how STL (and LOESS) is calculated can be found in Cleveland, Cleveland, and Terpenning (1990).\nYou need to make two important decisions when using STL: the trend-cycle window and the seasonal window. These control how rapidly the trend-cycle and seasonal components can change, with smaller values allowing for more rapid changes.\nThe trend-cycle window is the number of consecutive observations you want to use to estimate the trend-cycle. It must be an odd number. A larger window results in a smoother trend-cycle line. Therefore, your model is less responsive to short-term fluctuations. A very large window can lead to oversmoothing, where some genuine cyclical variation is mistakenly pushed into the remainder component.\nA smaller window uses a smaller number of observations. This results in a more flexible or wiggly trend-cycle line, allowing it to closely follow rapid rises and falls in the data. A very small window can lead to overfitting, where the trend-cycle captures too much of the irregular or seasonal variation.\nIn general, you should use a number larger than the seasonal period of the data. For example, our seasonal pattern in US general election turnout rates runs over four years. Our trend cycle window should, therefore, be larger than four. Choosing the right window is a trade-off between capturing the true long-term movement and being overly sensitive to short-term noise.\nTo illustrate, Figure 4.12 shows the STL calculated with two different trend-cycle windows: a short one of seven, and a long one of 21. The longer window completely misses the dip during Obama’s second term and the subsequent mid-term election. (The dip is relegated to the remainder component.)\nWhich one should you use? Which ever one you think better represents the time series. We will discuss formal methods for comparing models later in the course, but your gut feeling (informed by your knowledge of the thing you are trying to model) is a wonderful asset. Trust it. For what it’s worth, I would pick the seven-year window.\n\n\n\n\n\n\n\n\nFigure 4.12\n\n\n\n\n\nThe seasonal window directly controls the rate at which the seasonal pattern is allowed to change over the length of the time series. It must also always be an odd number. A smaller window is more flexible. It allows the seasonal pattern to change more quickly over time. This is useful if you believe the seasonality is evolving or adapting (e.g., people’s holiday shopping habits are shifting). A larger window is less flexible or smoother. The seasonal pattern is held more constant over time. This is used if you believe the underlying seasonality is very stable. You can also set the seasonal window to be periodic or infinite. This forces the pattern to be completely fixed. The seasonal pattern is identical across all periods.\nFigure 4.13 compares a short (5 year), long (11 year), and periodic (fixed) window for US voter turnout. They are all very similar because the difference between voter turnout in presidential and mid-term elections has not changed all that much across these two-and-a-half decades of data.\n\n\n\n\n\n\n\n\nFigure 4.13\n\n\n\n\n\n\n\n4.3.2 Seasonally-adjusted data\nIf you do not care about the variation due to seasonality, you should remove it from your model of the relationship between time and our outcome of interest. This leaves you with the trend and remainder components. When we do this, we call the data “seasonally-adjusted”.\nYou should use seasonally-adjusted time series data to analyze underlying trends and compare movements between different time periods, as it removes the predictable, repeating patterns (like holiday shopping or weather effects) that naturally occur within a year. This allows you to see the “true” non-seasonal changes. It is useful for understanding short-term fluctuations beyond the usual patterns.\nHowever, if you want to find turning points in a series, and interpret any changes in direction, then you should use the trend-cycle component (as shown in Figure 4.10 for US voter turnouts) rather than the seasonally-adjusted data. The remainder component can distract from this analysis.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series_decomposed.html#footnotes",
    "href": "04_time_series_decomposed.html#footnotes",
    "title": "4  Finding Patterns Over Time",
    "section": "",
    "text": "I use a sample of 100,000 for illustrative purposes. Sadly, I can’t take an infinitely large sample.↩︎\nAutocorrelation coefficients will be Normally distributed when drawn from a large sample of any distribution!↩︎\nFor very noisy time series, variation in the remainder (\\(Var(R_t)\\)) might be larger than the variation in the seasonally-adjusted data (\\(Var(R_t + T_t)\\)). Hence, the floor of zero.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "04_time_series_decomposed.html#measuring-the-strength-of-trend-and-seasonality-in-a-time-series",
    "href": "04_time_series_decomposed.html#measuring-the-strength-of-trend-and-seasonality-in-a-time-series",
    "title": "4  Finding Patterns Over Time",
    "section": "4.4 Measuring the strength of trend and seasonality in a time series",
    "text": "4.4 Measuring the strength of trend and seasonality in a time series\nThis decomposition is additive: you can reconstruct the observed voter turnout rate by adding together the trend-cycle, seasonal, and remainder components. Formally:\n\\[\ny_t = T_t + S_t + R_t\n\\]\nWhere \\(y_t\\) is the observed value at time \\(t\\), \\(T_t\\) is the trend_cycle component, \\(S_t\\) is the seasonal component, and \\(R_t\\) is the remainder component.\nWe can isolate the strength of the trend-cycle component by looking at how much variation in the seasonally-adjusted data come from that component. If the data are strongly trended (most of the pattern we see is driven by the overall trend, rather than seasonality or random noise), the amount of variation in the remainder component relative to all variation in the seasonally-adjusted data should be small.\nA common measure of the strength of the trend in time series is, therefore:\n\\[\nF_T = max(0, 1 - \\frac{Var(R_t)}{Var(R_t + T_t)})\n\\]\nThis gives us a measure of the strength of the trend that lies between 0 and 1, with higher values indicating that the trend is driving the pattern we see in the data.3 The strength of seasonality is defined similarly, but with respect to the detrended data rather than the seasonally adjusted data:\n\\[\nF_S = max(0, 1 - \\frac{Var(R_t)}{Var(R_t + S_t)})\n\\]\nBefore we calculate the strength of trend and seasonality in US voter turnout, guess how you think they will compare. Do you think the time series is very seasonal? Or do you think the pattern is driven by that overall positive trend in turnout?\nLet’s first calculate these manually:\n\ndcmp &lt;- us_turnout_ts |&gt; \n  filter(state == \"United States\", year &gt;= 1998) |&gt; \n  model(stl = STL(vep_turnout_rate ~ season(period = \"4 years\", window = \"periodic\") + \n                    trend(window = 7))) |&gt; \n  components()\n\nstrength_trend &lt;- max(0, 1 - (var(dcmp$remainder) / var(dcmp$season_adjust)))\nstrength_trend\n\n[1] 0.6665958\n\nstrength_season &lt;- max(0, 1 - (var(dcmp$remainder) / var(dcmp$`season_4 years` + \n                                                           dcmp$remainder)))\nstrength_season\n\n[1] 0.947254\n\n\nUS voter turnout is strongly seasonal and moderately trended. This passes my vibe check!\n\n\n\n\nCleveland, Robert B., William S. Cleveland, and Irma Terpenning. 1990. “STL: a seasonal-trend decomposition procedure based on loess.” Journal of official statistics 6 (1): 333.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Finding Patterns Over Time</span>"
    ]
  },
  {
    "objectID": "05_time_series_forecasts.html",
    "href": "05_time_series_forecasts.html",
    "title": "5  Time Series Regression Models",
    "section": "",
    "text": "5.1 Linear regression models\nNow that we have a good understanding of our time series, we want to start modelling relationships within it. What, in the past, has made our outcomes of interest rise and fall? Once we can answer that question, we can begin to try to predict the future.\nThis chapter introduces time series regression models.\nTo begin, we will focus on linear regression models. These models assume that the predicted effect of a change in our predictor on the outcome is the same no matter the value of the predictor. For example, we assume that a country’s GDP will grow at the same rate across all years.\nThis is a stringent assumption, but there are many cases where it is appropriate. If you are lucky enough to be modelling something with a linear relationship, you get to use a model that is intuative and (relatively) easy to interpret. The upside is large.\nLet’s introduce this model with one such example of a linear relationship. We are going to look at the relationship between baseball teams’ winning percentage and their run differential.\nA team’s winning percentage is simply the proportion of games that win. For example, if a team wins six of the 10 games they have played, their winning percentage is 60 percent. Their run differential is the difference between the number of runs they score and concede. So if a team makes 12 runs but their opponent scores 16, their run differential will be -4.\nLet’s take a look at this relationship across all teams’ seasons from 2000:\nTeams |&gt; \n  filter(yearID &gt;= 2000) |&gt; \n  transmute(yearID, teamID, RD = R - RA, WPct = W / G) |&gt; \n  as_tsibble(index = yearID, key = teamID) |&gt; \n  ggplot(aes(x = RD, y = WPct)) + \n  geom_point()\nThat’s a strong positive relationship. Teams with a high run differential tended to win most of their games. Teams with a low differential tended to lose. In general, this relationship looks linear: I could draw a straight line through those dots and capture the general trend within them very well.\nSo, we’re going to assume the relationship is linear and we can, therefore, model it using linear regression. To do this, we are going to focus on one team: my sweet, beleaguered Nats. Let’s look at their performance since entering the league in their current form in 2005:\nnats_ts &lt;- Teams |&gt; \n  filter(name == \"Washington Nationals\", yearID &gt;= 2005) |&gt; \n  transmute(yearID, RD = R - RA, WPct = W / G) |&gt; \n  as_tsibble(index = yearID)\n\nautoplot(nats_ts, WPct)\nAfter a slow start, they entered the glory years. These years culminated in the Nats winning the World Series in 2019. We made Screech so proud! After that, we took a downfall. I don’t even want to talk about this season. It’s a good thing it’s not in the data set.\nSo, do the Nats follow the general trend of tending to win lots of games in seasons in which they scored high run differentials?\nggplot(nats_ts, aes(x = RD, y = WPct)) + \n  geom_point()\nIt looks to be the case. We tended to win a high proportion of our games in the seasons in which we scored high run differentials. Conversely, we tended to win a low proportion of our games in the seasons we scored low run differentials.\nWe can model that using linear least squares regression:\nnats_m &lt;- model(nats_ts, TSLM(WPct ~ RD))\n\nreport(nats_m)\n\nSeries: WPct \nModel: TSLM \n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.054879 -0.015794  0.005792  0.020122  0.034770 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.932e-01  6.037e-03   81.68  &lt; 2e-16 ***\nRD          6.183e-04  4.785e-05   12.92 1.52e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02661 on 18 degrees of freedom\nMultiple R-squared: 0.9027, Adjusted R-squared: 0.8973\nF-statistic:   167 on 1 and 18 DF, p-value: 1.5174e-10\nintercept_coef &lt;- tidy(nats_m) |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  pull(estimate)\n\nRD_coef &lt;- tidy(nats_m) |&gt; \n  filter(term == \"RD\") |&gt; \n  pull(estimate)\nggplot(nats_ts, aes(x = RD, y = WPct)) + \n  geom_point() + \n  geom_line(aes(y = augment(nats_m)$.fitted)) + \n  theme_minimal()\nWe can take advantage of broom::augment() to calculate the predicted winning percentage for each given run differential, and how far that predicted value is from what we observed.\naugment(nats_m) |&gt; \n  select(yearID, WPct, .fitted, .resid) |&gt; \n  knitr::kable()\n\n\n\n\nyearID\nWPct\n.fitted\n.resid\n\n\n\n\n2005\n0.5000000\n0.4721360\n0.0278640\n\n\n2006\n0.4382716\n0.4152499\n0.0230217\n\n\n2007\n0.4506173\n0.4251431\n0.0254742\n\n\n2008\n0.3664596\n0.3793869\n-0.0129273\n\n\n2009\n0.3641975\n0.3917534\n-0.0275559\n\n\n2010\n0.4259259\n0.4393646\n-0.0134387\n\n\n2011\n0.4968944\n0.4814109\n0.0154835\n\n\n2012\n0.6049383\n0.5778699\n0.0270683\n\n\n2013\n0.5308642\n0.5117089\n0.0191553\n\n\n2014\n0.5925926\n0.5741600\n0.0184326\n\n\n2015\n0.5123457\n0.5352054\n-0.0228597\n\n\n2016\n0.5864198\n0.5865265\n-0.0001068\n\n\n2017\n0.5987654\n0.5840532\n0.0147122\n\n\n2018\n0.5061728\n0.5481902\n-0.0420174\n\n\n2019\n0.5740741\n0.5852899\n-0.0112158\n\n\n2020\n0.4333333\n0.4882125\n-0.0548792\n\n\n2021\n0.4012346\n0.4337997\n-0.0325651\n\n\n2022\n0.3395062\n0.3373406\n0.0021655\n\n\n2023\n0.4382716\n0.4035017\n0.0347699\n\n\n2024\n0.4382716\n0.4288531\n0.0094185\naugment(nats_m) |&gt; \n  ggplot(aes(x = yearID)) +\n  geom_line(aes(y = WPct), colour = \"lightgrey\") + \n  geom_line(aes(y = .fitted), colour = \"darkred\") + \n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Time Series Regression Models</span>"
    ]
  },
  {
    "objectID": "05_time_series_forecasts.html#linear-regression-models",
    "href": "05_time_series_forecasts.html#linear-regression-models",
    "title": "5  Time Series Regression Models",
    "section": "",
    "text": "Note\n\n\n\n\n\nNote, this is equivalent to running:\n\nlm(WPct ~ RD, data = nats_ts)\n\n\nCall:\nlm(formula = WPct ~ RD, data = nats_ts)\n\nCoefficients:\n(Intercept)           RD  \n  0.4931591    0.0006183",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Time Series Regression Models</span>"
    ]
  },
  {
    "objectID": "05_time_series_forecasts.html#extending-this",
    "href": "05_time_series_forecasts.html#extending-this",
    "title": "5  Time Series Regression Models",
    "section": "5.2 Extending this",
    "text": "5.2 Extending this",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Time Series Regression Models</span>"
    ]
  },
  {
    "objectID": "05_time_series_forecasts.html#is-this-a-good-model",
    "href": "05_time_series_forecasts.html#is-this-a-good-model",
    "title": "5  Time Series Regression Models",
    "section": "5.3 Is this a good model?",
    "text": "5.3 Is this a good model?\nThe differences between our predicted values and the ones that happened in the real world are known as the training-set errors or residuals.\nWith time-series data, the value of your variable at time \\(t\\) is probably very similar to its value at time \\(t-1\\). Therefore, when fitting a regression model to time-series data, it is common to find autocorrelation in the residuals. In this case, the estimated model violates the assumption of no autocorrelation in the errors. While the forecasts are not wrong, their prediction intervals can be larger than they need to be.\n\ngg_tsresiduals(nats_m)\n\n\n\n\n\n\n\n\nThe time plot shows changing variation over time. This heteroscedasticity will potentially make the prediction interval coverage inaccurate.\nThe autocorrelation plot shows no significant spikes. It is unlikely to have any noticeable impact on the forecasts or the prediction intervals.\nOur residuals are skewed to the left, which may also affect the coverage probability of the prediction intervals.\nWe would expect the residuals to be randomly scattered without showing any systematic patterns. A simple and quick way to check this is to examine scatterplots of the residuals against each of the predictor variables. If these scatterplots show a pattern, then the relationship may be non-linear and the model will need to be modified accordingly.\nHappily, ours shows no pattern:\n\naugment(nats_m) |&gt; \n  left_join(nats_ts, by = join_by(yearID, WPct)) |&gt; \n  ggplot(aes(x = RD, y = .resid)) + \n  geom_point() + \n  labs(x = \"Run differential\", y = \"Residuals\")\n\n\n\n\n\n\n\n\nYou should also plot your residuals against your fitted values to see if a pattern exists. If there is a pattern, there may be heteroscedasticity in the errors. This means that the variance of the residuals may not be constant. Happily again, no pattern exists:\n\naugment(nats_m) |&gt; \n  ggplot(aes(x = .fitted, y = .resid)) + \n  geom_point() + \n  labs(x = \"Fitted\", y = \"Residuals\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Time Series Regression Models</span>"
    ]
  },
  {
    "objectID": "05_time_series_forecasts.html#the-nats-performance",
    "href": "05_time_series_forecasts.html#the-nats-performance",
    "title": "5  Time Series Regression Models",
    "section": "5.2 The Nats performance",
    "text": "5.2 The Nats performance\nTo do this, we are going to focus on one team: my sweet, beleaguered Nats. Let’s look at their performance since entering the league in their current form in 2005:\n\nnats_ts &lt;- Teams |&gt; \n  filter(name == \"Washington Nationals\", yearID &gt;= 2005) |&gt; \n  transmute(yearID, RD = R - RA, WPct = W / G) |&gt; \n  as_tsibble(index = yearID)\n\nautoplot(nats_ts, WPct)\n\n\n\n\n\n\n\n\nAfter a slow start, they entered the glory years. These years culminated in the Nats winning the World Series in 2019. We made Screech so proud! After that, we took a downfall. I don’t even want to talk about this season. It’s a good thing it’s not in the data set.\nSo, do the Nats follow the general trend of tending to win lots of games in seasons in which they scored high run differentials?\n\nggplot(nats_ts, aes(x = RD, y = WPct)) + \n  geom_point()\n\n\n\n\n\n\n\n\nIt looks to be the case. We tended to win a high proportion of our games in the seasons in which we scored high run differentials. Conversely, we tended to win a low proportion of our games in the seasons we scored low run differentials.\nWe can model that using linear least squares regression:\n\nnats_m &lt;- model(nats_ts, TSLM(WPct ~ RD))\n\nreport(nats_m)\n\nSeries: WPct \nModel: TSLM \n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.054879 -0.015794  0.005792  0.020122  0.034770 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 4.932e-01  6.037e-03   81.68  &lt; 2e-16 ***\nRD          6.183e-04  4.785e-05   12.92 1.52e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02661 on 18 degrees of freedom\nMultiple R-squared: 0.9027, Adjusted R-squared: 0.8973\nF-statistic:   167 on 1 and 18 DF, p-value: 1.5174e-10\n\n\n\nintercept_coef &lt;- tidy(nats_m) |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  pull(estimate)\n\nRD_coef &lt;- tidy(nats_m) |&gt; \n  filter(term == \"RD\") |&gt; \n  pull(estimate)\n\n\nggplot(nats_ts, aes(x = RD, y = WPct)) + \n  geom_point() + \n  geom_line(aes(y = augment(nats_m)$.fitted)) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can take advantage of broom::augment() to calculate the predicted winning percentage for each given run differential, and how far that predicted value is from what we observed.\n\naugment(nats_m) |&gt; \n  select(yearID, WPct, .fitted, .resid) |&gt; \n  knitr::kable()\n\n\n\n\nyearID\nWPct\n.fitted\n.resid\n\n\n\n\n2005\n0.5000000\n0.4721360\n0.0278640\n\n\n2006\n0.4382716\n0.4152499\n0.0230217\n\n\n2007\n0.4506173\n0.4251431\n0.0254742\n\n\n2008\n0.3664596\n0.3793869\n-0.0129273\n\n\n2009\n0.3641975\n0.3917534\n-0.0275559\n\n\n2010\n0.4259259\n0.4393646\n-0.0134387\n\n\n2011\n0.4968944\n0.4814109\n0.0154835\n\n\n2012\n0.6049383\n0.5778699\n0.0270683\n\n\n2013\n0.5308642\n0.5117089\n0.0191553\n\n\n2014\n0.5925926\n0.5741600\n0.0184326\n\n\n2015\n0.5123457\n0.5352054\n-0.0228597\n\n\n2016\n0.5864198\n0.5865265\n-0.0001068\n\n\n2017\n0.5987654\n0.5840532\n0.0147122\n\n\n2018\n0.5061728\n0.5481902\n-0.0420174\n\n\n2019\n0.5740741\n0.5852899\n-0.0112158\n\n\n2020\n0.4333333\n0.4882125\n-0.0548792\n\n\n2021\n0.4012346\n0.4337997\n-0.0325651\n\n\n2022\n0.3395062\n0.3373406\n0.0021655\n\n\n2023\n0.4382716\n0.4035017\n0.0347699\n\n\n2024\n0.4382716\n0.4288531\n0.0094185\n\n\n\n\n\n\naugment(nats_m) |&gt; \n  ggplot(aes(x = yearID)) +\n  geom_line(aes(y = WPct), colour = \"lightgrey\") + \n  geom_line(aes(y = .fitted), colour = \"darkred\") + \n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Time Series Regression Models</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#step-1.-prepare-your-data",
    "href": "01_whole_game.html#step-1.-prepare-your-data",
    "title": "1  The Whole Game - A Forecasting Roadmap",
    "section": "1.2 Step 1. Prepare Your Data",
    "text": "1.2 Step 1. Prepare Your Data\nYou first need to prepare your data for analysis. This can often be the most time-consuming part of your data analysis process. Happily, I have cleaned our data for you.\nThe last step in this process is to convert your data set into a tsibble object, which has features that make time-series analysis easier.\n\ntrump_approval &lt;- read_rds(here::here(\"data\", \"trump_approval.rds\")) |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tsibble()\n\ntrump_approval\n\n# A tsibble: 36 x 2 [1W]\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W05      49\n 2 2025 W06      46\n 3 2025 W07      46\n 4 2025 W08      50\n 5 2025 W09      48\n 6 2025 W10      48\n 7 2025 W11      47\n 8 2025 W12      45\n 9 2025 W13      48\n10 2025 W14      46\n# ℹ 26 more rows",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game - A Forecasting Roadmap</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#step-1-prepare-your-data",
    "href": "01_whole_game.html#step-1-prepare-your-data",
    "title": "1  The Whole Game",
    "section": "1.3 Step 1: Prepare Your Data",
    "text": "1.3 Step 1: Prepare Your Data\nBefore any analysis can begin, you must first wrestle your data into a usable format. This step, which often involves cleaning messy spreadsheets, merging different data sources, and handling missing values, is often the most time-consuming part of any data science project.\nIn time series analysis, there is a crucial final step: transforming your regular data frame into a special object that can handle time. We will use the tsibble object in R. The ‘ts’ stands for “time series.” A tsibble is essentially a smart data frame that knows:\n\nWhat the time variable is (e.g., date)\nHow frequently the data occur (e.g., weekly)\nIn what order the data should be processed\n\nWithout this structure, R simply sees a list of numbers. With it, R sees a chronological history that can be modeled. In this course, we will mostly provide you with clean data, but understanding the importance of the tsibble structure is vital.\n\ntrump_approval &lt;- read_rds(here::here(\"data\", \"trump_approval.rds\")) |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tsibble()\n\ntrump_approval\n\n# A tsibble: 38 x 2 [1W]\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W05      49\n 2 2025 W06      46\n 3 2025 W07      46\n 4 2025 W08      50\n 5 2025 W09      48\n 6 2025 W10      48\n 7 2025 W11      47\n 8 2025 W12      45\n 9 2025 W13      48\n10 2025 W14      46\n# ℹ 28 more rows",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#step-2-plot-your-data",
    "href": "01_whole_game.html#step-2-plot-your-data",
    "title": "1  The Whole Game",
    "section": "1.4 Step 2: Plot your data",
    "text": "1.4 Step 2: Plot your data\nThe very first analytical step is always visual: plot your data. Your eyes are often the best tool for identifying patterns that statistical formulas might miss. By visualizing the time series, you can better detect three major features:\n\nTrend: Is the approval rating generally going up, staying flat, or going down over the long run?\nSeasonality: Are there patterns that repeat over fixed, known intervals (e.g., does approval always dip during the summer recess or spike after a major national holiday)? In weekly polling data, true seasonality might be rare, but understanding the concept is key for other datasets.\nCycles: Are there longer, non-fixed patterns that don’t repeat at a perfect interval, often linked to the political or economic cycle?\n\nPlotting the data allows you to get an intuitive feel for the underlying story your model will try to capture. We call this process Exploratory Data Analysis (EDA), and it is the foundation of selecting an appropriate forecasting model.\nFigure 4.1 shows Mr Trump’s approval rating since his first day in office. We can see that his approval rating is decreasing over his term in office.\n\nautoplot(trump_approval) + \n  theme_minimal() + \n  labs(x = \"Date\",\n       y = \"Approval rating (%)\",\n       caption = \"Data source: The Economist/YouGov\") + \n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\nFigure 1.1: Mr Trump’s approval ratings since entering his second term in office.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#step-3-specify-your-model",
    "href": "01_whole_game.html#step-3-specify-your-model",
    "title": "1  The Whole Game",
    "section": "1.5 Step 3: Specify your model",
    "text": "1.5 Step 3: Specify your model\nThe model specification step is where you formally decide on the statistical story you want to tell about your data. A statistical model is a simplified mathematical representation of reality. Since reality is messy, the model abstracts away the noise to focus on the signal—the core pattern.\nIn this course, we will explore many different ‘stories’:\n\nSimple Trend Models (like the one below): The story is that approval ratings change by a fixed, constant amount over time, plus some random, unpredictable noise.\nModels based on previous values (Autoregressive models): The story is that the best predictor of today’s approval rating is yesterday’s approval rating.\nAdvanced Models: Combinations of the above that capture both trend and complex, changing relationships over time.\n\nFor this initial demonstration, we will select the most straightforward story: a linear trend model. This model assumes that the change in approval rating over time can be represented by a straight line.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#step-4-train-your-model",
    "href": "01_whole_game.html#step-4-train-your-model",
    "title": "1  The Whole Game",
    "section": "1.6 Step 4: Train your model",
    "text": "1.6 Step 4: Train your model\nOnce you specify your model, you must train it. Training is the process of using your historical data (the observed approval ratings) to calculate the precise parameters that make your model’s “story” fit the data and capture that core underlying pattern.\nIn the case of our linear trend model, training involves finding the best possible straight line—specifically, calculating the best starting point (intercept) and the best rate of change (slope) that minimizes the vertical distance between the line and every observed data point.\nThe model() function in the fable package handles this training step automatically. It ingests your time series data and outputs a trained object that contains all the necessary parameters for prediction.\n\nfit &lt;- trump_approval |&gt; \n  model(linear_trend = TSLM(approve ~ trend()))\n\nWe now have a trained statistical model of the President’s approval rating over time.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#step-5-evaluate-your-models-performance",
    "href": "01_whole_game.html#step-5-evaluate-your-models-performance",
    "title": "1  The Whole Game",
    "section": "1.7 Step 5: Evaluate your model’s performance",
    "text": "1.7 Step 5: Evaluate your model’s performance\nHow do you know if your model’s story is any good? You certainly can’t trust a model that only works on the data it was trained on! The key step in forecasting is rigorously evaluating the model’s performance on data it has never seen before.\nTo do this, we often set aside the most recent historical data (the “test set” or “holdout set”). We then ask our trained model to “predict” these past, unseen values. We then compare the model’s predictions to the actual observed values. The difference between the prediction and the actual outcome is called the forecast error.\nEvaluating these errors—how big they are, if they are systematic, and if they are acceptable—is the only way to gain confidence in a model. If the errors are too large or follow a clear pattern (e.g., the model always overestimates the rating), the model is not trustworthy, and you must go back to Step 3: Specify Your Model and try a new, better story.\nThe fable package provides the accuracy() function to quickly summarize these errors. To properly use it, we first need to split our data, train the model on the training set, and then compare its forecasts to the test set.\n\n# 1. Split the data: Use all but the last 10 weeks for training\nn_test &lt;- 10\ntrump_train &lt;- trump_approval |&gt; slice(1:(n() - n_test))\ntrump_test &lt;- trump_approval |&gt; slice((n() - n_test + 1):n())\n\n# 2. Train the model on the training data only\nfit_train &lt;- trump_train |&gt; \n  model(linear_trend = TSLM(approve ~ trend()))\n\n# 3. Forecast for the test period\nforecast_test &lt;- forecast(fit_train, new_data = trump_test)\n\n# 4. Show the accuracy metrics\naccuracy(forecast_test, trump_approval) |&gt; \n  select(.model, RMSE, MAE)\n\n# A tibble: 1 × 3\n  .model        RMSE   MAE\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 linear_trend  2.11  1.97\n\n\nWe will dedicate a whole chapter to interpreting these metrics like RMSE (Root Mean Squared Error) and MAE (Mean Absolute Error), but for now, just know that lower numbers mean a better-performing model.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#step-6-forecast",
    "href": "01_whole_game.html#step-6-forecast",
    "title": "1  The Whole Game",
    "section": "1.8 Step 6: Forecast",
    "text": "1.8 Step 6: Forecast\nIf, and only if, you are happy with your model’s performance on the holdout data, you can use it to predict future, unknown values. This final step is called forecasting.\nWhen you forecast, you are typically interested in two things:\n\nThe Point Estimate (.mean): This is the model’s single best guess—the center of the prediction. For instance, the model’s best guess for the President’s approval rating in the future.\nThe Prediction Interval: This is the crucial measure of uncertainty. It provides a range of plausible values within which the actual outcome is likely to fall (e.g., 95 percent of the time). A good forecaster never provides a single number; they always provide this interval, acknowledging that the future is inherently uncertain.\n\nFor example, we will now forecast the President’s approval ratings for the next 100 weeks using our simple linear trend model:\n\ntrump_approval_forecast &lt;- forecast(fit, h = \"100 weeks\")\ntrump_approval_forecast\n\n# A fable: 100 x 4 [1W]\n# Key:     .model [1]\n   .model           date\n   &lt;chr&gt;          &lt;week&gt;\n 1 linear_trend 2025 W43\n 2 linear_trend 2025 W44\n 3 linear_trend 2025 W45\n 4 linear_trend 2025 W46\n 5 linear_trend 2025 W47\n 6 linear_trend 2025 W48\n 7 linear_trend 2025 W49\n 8 linear_trend 2025 W50\n 9 linear_trend 2025 W51\n10 linear_trend 2025 W52\n# ℹ 90 more rows\n# ℹ 2 more variables: approve &lt;dist&gt;, .mean &lt;dbl&gt;\n\n\nThe output above shows your forecast: the .mean is your point estimate, and the columns with 80% and 95% confidence levels define the prediction intervals.\nFinally, we plot these predicted approval ratings alongside the observed history to see the whole story:\n\ntrump_approval_forecast |&gt; \n  autoplot(trump_approval) + \n  theme_minimal() + \n  labs(x = \"Date\",\n       y = \"Approval rating (%)\",\n       caption = \"Data source: The Economist/YouGov\") + \n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\nFigure 1.2: Mr Trump’s approval ratings, both observed and predicted.\n\n\n\n\n\nOur simple model predicts that the overall trend of declining popularity will continue. Notice how the uncertainty (the shaded dark and light blue areas) gets wider the further out we look. This intuitively makes sense: it’s easier to be sure about next week than next year.\nThis entire process—from preparing the data to evaluating models and communicating uncertainty—is what this course is about. You will acquire the skills needed to make predictions informed by what has happened in the past and understand the level of risk you are taking. Let’s get started!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game</span>"
    ]
  },
  {
    "objectID": "01_whole_game.html#our-illustrative-example-the-approval-rating-rollercoaster",
    "href": "01_whole_game.html#our-illustrative-example-the-approval-rating-rollercoaster",
    "title": "1  The Whole Game",
    "section": "1.2 Our Illustrative Example: The Approval Rating Rollercoaster",
    "text": "1.2 Our Illustrative Example: The Approval Rating Rollercoaster\nTo illustrate the forecasting process, we will look at one of the most dynamic and closely watched metrics in political science: the current US President’s approval rating across their current term in office.\nA President’s approval rating is not just a vanity metric: it is a critical indicator of political capital, legislative success, and re-election prospects. The data we will use are collected on a near-weekly basis by the polling firm YouGov on behalf of The Economist. It provides the percentage of respondents from a representative sample of the US voting population who approve of President Trump’s performance in office.\nThis dataset is a perfect time series example: the data points are ordered in time, and each observation is influenced by the one that came before it. The challenge is clear: given the up-and-down rollercoaster of events, can we predict where the President’s popularity will be next week, next month, or next year?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The Whole Game</span>"
    ]
  },
  {
    "objectID": "02_forecasting.html#what-can-be-forecast",
    "href": "02_forecasting.html#what-can-be-forecast",
    "title": "2  The Forecasting Landscape",
    "section": "",
    "text": "2.1.1 The Quantifiable World\nThe core requirement for a successful forecasting project is a clear, repeatable, and quantifiable outcome. In political science and sports, this means moving beyond subjective judgment and focusing on the numbers:\n\n\n\n\n\n\n\nField\nQuantifiable Outcomes\n\n\n\n\nPolitical Science\nElection vote shares, presidential approval ratings, duration of wars/conflicts, legislative success rates (e.g., probability of a bill passing), economic indicators (GDP growth, unemployment).\n\n\nSports Analytics\nGame outcomes (win/loss probability), player performance metrics (e.g., Expected Goals, next season’s home runs), injury likelihood, fantasy points scored, and betting line movements.\n\n\n\nThese fields are data-rich laboratories, making them perfect for learning predictive modeling.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Forecasting Landscape</span>"
    ]
  },
  {
    "objectID": "02_forecasting.html#goals-and-time-horizons",
    "href": "02_forecasting.html#goals-and-time-horizons",
    "title": "2  The Forecasting Landscape",
    "section": "2.2 Goals and Time Horizons",
    "text": "2.2 Goals and Time Horizons\nIn forecasting, the “when” and “why” are just as important as the “what.” Every project requires defining your time horizon and clarifying whether your primary goal is pure prediction or deeper understanding.\n\n2.2.1 Defining the Time Horizon\nThe time frame of your forecast drastically changes the model you should use.\n\nShort-Term Forecasts (Hours/Days/Weeks): These focus on immediate dynamics and momentum. Examples include predicting the minute-by-minute movement of a stock price, or, in sports, calculating the Expected Points Added (EPA) for the very next play in an NFL game. These forecasts rely heavily on the very recent past and high-frequency data.\nMedium-Term Forecasts (Months/Quarters): This is the sweet spot for many political and economic forecasts. Predicting the President’s approval rating over the next three months or a team’s win total over a season requires capturing trends and known seasonal/cyclical factors.\nLong-Term Forecasts (Years/Decades): These are the most challenging and least certain. They involve structural models, like predicting the outcome of the next US presidential election a year in advance, or projecting the career arc and future salary of a rookie basketball player. Here, major structural variables (like demographic changes or economic recessions) matter more than daily noise.\n\n\n\n2.2.2 Prediction vs. Explanation\nForecasting models serve two primary goals:\n\nPure Prediction: This goal is focused solely on accuracy. If a complex, black-box machine learning model gives you the most accurate vote-share prediction, you use it, even if you can’t explain why it chose that number. This is often the goal of prediction markets or betting exchanges.\nExplanation (Causality): This goal focuses on understanding. You might accept a slightly less accurate model if it clearly tells you that “a one percentage point change in GDP growth leads to a two percentage point increase in incumbent vote share.” Political scientists often prioritize these explanatory models to test and advance theory.\n\nA great forecaster knows the difference and selects the right model for the job.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Forecasting Landscape</span>"
    ]
  },
  {
    "objectID": "02_forecasting.html#data-and-methods",
    "href": "02_forecasting.html#data-and-methods",
    "title": "2  The Forecasting Landscape",
    "section": "2.3 Data and Methods",
    "text": "2.3 Data and Methods\nAt the heart of every good forecast is robust data and a carefully chosen mathematical technique. In this course, we will primarily use the tidyverse ecosystem in R, a set of tools designed for clean, reproducible data science.\n\n2.3.1 The Data Foundation: Time Series\nOur focus is on time series data , where data points are ordered and dependent on the past. To handle this, we use the tsibble object, which is like a smart spreadsheet that remembers the sequence.\n\n\n2.3.2 Core Forecasting Methods\nWhile we’ll cover many methods in depth, most fall into a few categories:\n\nRegression Models (The Storytellers): These establish linear or non-linear relationships between variables. The simple Linear Trend Model we saw in the previous chapter assumes the future is a straight-line continuation of the past. More complex regression models (like those used for election forecasting) include dozens of predictors, such as economic growth, presidential approval, and partisan affiliation, to predict the final vote share.\nSmoothing and Decomposition (The Cleaners): Methods like simple exponential smoothing or STL decomposition help us strip away the noise and random variation to reveal the pure, underlying trend and any seasonal patterns. This is often the first step in modeling data with strong, predictable cycles (like retail sales or airline traffic).\nMachine Learning (The Optimizers): Advanced techniques like neural networks and Random Forests excel at finding complex, non-linear relationships in massive datasets. These are often used in sports to predict player movement or tactical outcomes where the interactions are too intricate for simple regression.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Forecasting Landscape</span>"
    ]
  },
  {
    "objectID": "02_forecasting.html#case-studies-in-predictive-power",
    "href": "02_forecasting.html#case-studies-in-predictive-power",
    "title": "2  The Forecasting Landscape",
    "section": "2.4 Case Studies in Predictive Power",
    "text": "2.4 Case Studies in Predictive Power\nLet’s look at two high-stakes areas where forecasting has fundamentally changed the conversation.\n\n2.4.1 Political Science - Election Forecasting\nOne of the most popular and scrutinized areas of political forecasting is predicting US presidential elections. Early models often relied on just two to three variables, reflecting the core explanatory goal: for example, the economy and the incumbent’s standing.\n\n2.4.1.1 The “Fundamentals” Model\nPolitical scientists discovered that the election outcome, when predicted months in advance, is largely determined by the fundamentals: the state of the economy (GDP growth, job numbers) and whether the country feels it’s “time for a change.” These models, despite their simplicity, consistently outperform early public polls because they recognize that voters haven’t fully focused on the race yet, but the underlying conditions are already set.\n\n\n2.4.1.2 The Polling Aggregation Model\nAs Election Day nears, the best forecasts shift to incorporating hundreds or thousands of public opinion polls, weighted by quality, recency, and sample size. This is what sites like FiveThirtyEight popularized. Here, the challenge is no longer about finding the causes of the vote, but about accurately estimating the current state of the vote and managing the uncertainty of who will actually turn out.\n\n\n\n2.4.2 Sports Analytics - Expected Goals (xG)\nSports analytics, often called the “Moneyball” revolution, is a hotbed of predictive modeling. Consider the metric Expected Goals (xG) in soccer.\nBefore xG, a missed shot was just a “miss.” Now, we ask: how likely was that shot to be a goal?\n\n2.4.2.1 The xG Methodology\nxG is a predictive model (often a logistic regression or machine learning model) trained on thousands of shots. For any new shot, it calculates the probability that the shot will result in a goal based on historical data. The variables in the model are factors like:\n\nDistance to the goal\nAngle to the goal\nType of pass that created the opportunity\nWhether it was a “big chance” or a header\nHow many defenders were between the shooter and the goal\n\nIf a player takes a shot that has a 0.5 (50%) chance of being a goal, their xG increases by 0.5, regardless of whether the shot actually goes in. Teams use xG to forecast:\n\nSustainable Performance: Is a team scoring more goals than their xG suggests? If so, they are likely to regress (score less) in the future.\nTactical Efficiency: Where on the field are we creating the highest xG chances? This helps inform in-game and transfer market decisions.\n\nThe xG metric perfectly demonstrates how forecasting models don’t just predict the final score; they help managers understand the underlying quality and consistency of performance, managing the uncertainty of luck and randomness inherent in any single game.\nThroughout this course, you will build the skills to tackle predictive problems just like these, moving from simple trend-based models to complex, variable-rich analytical tools.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The Forecasting Landscape</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#the-foundation-the-tsibble-object",
    "href": "03_time_series_r.html#the-foundation-the-tsibble-object",
    "title": "3  The Toolkit: R for Time Series",
    "section": "",
    "text": "3.1.1 Why a tsibble?\nA standard tibble or data.frame treats columns like date or week as just text or numbers. A tsibble (Time Series Tibble) is a smart data structure. It forces you to define what is being measured and when it was measured. It automatically flags missing time points, helps manage multiple concurrent time series, and ensures your models treat the data’s time dependency correctly.\n\n\n3.1.2 Indexes and Keys: The DNA of a tsibble\nEvery tsibble has two defining features:\n\n3.1.2.1 The Index (The When)\nThe index is the column that specifies the time point of the observation. The tsibble package provides several helper functions to convert standard dates/times into time-aware indices:\n\n\n\nFrequency\nFunction\nExample\n\n\n\n\nYearly\nyear()\nyear(2025)\n\n\nQuarterly\nyearquarter()\nyearquarter(2025 Q3)\n\n\nMonthly\nyearmonth()\nyearmonth(2025 Oct)\n\n\nWeekly\nyearweek()\nyearweek(2025 W42)\n\n\n\nLet’s use the provided political science data to demonstrate. We convert the date column into a weekly index using yearweek() and then convert the entire tibble into a tsibble.\n\n# Load a standard tibble of Mr. Trump's approval ratings\ntrump_approval &lt;- read_rds(here::here(\"data\", \"trump_approval.rds\"))\ntrump_approval\n\n# A tibble: 38 × 2\n   date       approve\n   &lt;date&gt;       &lt;dbl&gt;\n 1 2025-10-13      40\n 2 2025-10-06      39\n 3 2025-09-29      40\n 4 2025-09-22      39\n 5 2025-09-08      41\n 6 2025-09-02      41\n 7 2025-09-15      39\n 8 2025-08-04      41\n 9 2025-08-25      41\n10 2025-08-18      40\n# ℹ 28 more rows\n\n\n\n# Convert it to a tsibble, setting the index explicitly\ntrump_approval_ts &lt;- trump_approval |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tsibble()\n\ntrump_approval_ts\n\n# A tsibble: 38 x 2 [1W]\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W05      49\n 2 2025 W06      46\n 3 2025 W07      46\n 4 2025 W08      50\n 5 2025 W09      48\n 6 2025 W10      48\n 7 2025 W11      47\n 8 2025 W12      45\n 9 2025 W13      48\n10 2025 W14      46\n# ℹ 28 more rows\n\n\nNotice how the tsibble output clearly labels date as the Index and immediately tells us the data is collected weekly.\n\n\n3.1.2.2 The Key (The What)\nIn many forecasting projects, you deal with multiple, independent time series simultaneously (e.g., all 30 NBA teams, or all 50 US states). The Key is the column that identifies which individual series each observation belongs to.\nThe Australian Football League (AFL) data provides a great example. We want to track 18 different teams over the season’s 25 rounds.\n\n# Load data on each AFL team's performance\nafl_ladder &lt;- read_rds(here::here(\"data\", \"afl_ladder.rds\"))\n\n# Convert to a tsibble, defining 'team' as the key and 'round_number' as the index\nafl_ladder_ts &lt;- afl_ladder |&gt; \n  as_tsibble(key = team, index = round_number)\n\nafl_ladder_ts\n\n# A tsibble: 450 x 8 [1]\n# Key:       team [18]\n   season team     round_number season_points score_for score_against percentage\n    &lt;dbl&gt; &lt;chr&gt;           &lt;int&gt;         &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n 1   2024 Adelaide            1             0         0             0      0    \n 2   2024 Adelaide            2             0        54            60      0.9  \n 3   2024 Adelaide            3             0       131           156      0.840\n 4   2024 Adelaide            4             0       165           225      0.733\n 5   2024 Adelaide            5             0       228           303      0.752\n 6   2024 Adelaide            6             4       328           401      0.818\n 7   2024 Adelaide            7             4       403           479      0.841\n 8   2024 Adelaide            8             8       541           560      0.966\n 9   2024 Adelaide            9            12       619           608      1.02 \n10   2024 Adelaide           10            14       709           698      1.02 \n# ℹ 440 more rows\n# ℹ 1 more variable: ladder_position &lt;int&gt;\n\n\nThe output now shows Key: team [18], meaning we have 18 unique time series bundled together. This allows us to run one single model command to fit 18 separate models—one for each team!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#indexes-and-keys-the-dna-of-a-tsibble",
    "href": "03_time_series_r.html#indexes-and-keys-the-dna-of-a-tsibble",
    "title": "3  The Toolkit: R for Time Series",
    "section": "3.2 Indexes and Keys: The DNA of a tsibble",
    "text": "3.2 Indexes and Keys: The DNA of a tsibble\nEvery tsibble has two defining features:\n\n3.2.0.1 The Index (The When)\nThe index is the column that specifies the time point of the observation. The tsibble package provides several helper functions to convert standard dates/times into time-aware indices:\n\n\n\nFrequency\nFunction\nExample\n\n\n\n\nYearly\nyear()\nyear(2025)\n\n\nQuarterly\nyearquarter()\nyearquarter(2025 Q3)\n\n\nMonthly\nyearmonth()\nyearmonth(2025 Oct)\n\n\nWeekly\nyearweek()\nyearweek(2025 W42)\n\n\n\nLet’s use the provided political science data to demonstrate. We convert the date column into a weekly index using yearweek() and then convert the entire tibble into a tsibble.\n\n# Load a standard tibble of Mr. Trump's approval ratings\ntrump_approval &lt;- read_rds(here::here(\"data\", \"trump_approval.rds\"))\ntrump_approval\n\n# A tibble: 38 × 2\n   date       approve\n   &lt;date&gt;       &lt;dbl&gt;\n 1 2025-10-13      40\n 2 2025-10-06      39\n 3 2025-09-29      40\n 4 2025-09-22      39\n 5 2025-09-08      41\n 6 2025-09-02      41\n 7 2025-09-15      39\n 8 2025-08-04      41\n 9 2025-08-25      41\n10 2025-08-18      40\n# ℹ 28 more rows\n\n\n\n# Convert it to a tsibble, setting the index explicitly\ntrump_approval_ts &lt;- trump_approval |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tsibble()\n\ntrump_approval_ts\n\n# A tsibble: 38 x 2 [1W]\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W05      49\n 2 2025 W06      46\n 3 2025 W07      46\n 4 2025 W08      50\n 5 2025 W09      48\n 6 2025 W10      48\n 7 2025 W11      47\n 8 2025 W12      45\n 9 2025 W13      48\n10 2025 W14      46\n# ℹ 28 more rows\n\n\nNotice how the tsibble output clearly labels date as the Index and immediately tells us the data is collected weekly.\n\n\n3.2.1 The Key (The What)\nIn many forecasting projects, you deal with multiple, independent time series simultaneously (e.g., all 30 NBA teams, or all 50 US states). The Key is the column that identifies which individual series each observation belongs to.\nThe Australian Football League (AFL) data provides a great example. We want to track 18 different teams over the season’s 25 rounds.\n\n# Load data on each AFL team's performance\nafl_ladder &lt;- read_rds(here::here(\"data\", \"afl_ladder.rds\"))\n\n# Convert to a tsibble, defining 'team' as the key and 'round_number' as the index\nafl_ladder_ts &lt;- afl_ladder |&gt; \n  as_tsibble(key = team, index = round_number)\n\nafl_ladder_ts\n\n# A tsibble: 450 x 8 [1]\n# Key:       team [18]\n   season team     round_number season_points score_for score_against percentage\n    &lt;dbl&gt; &lt;chr&gt;           &lt;int&gt;         &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n 1   2024 Adelaide            1             0         0             0      0    \n 2   2024 Adelaide            2             0        54            60      0.9  \n 3   2024 Adelaide            3             0       131           156      0.840\n 4   2024 Adelaide            4             0       165           225      0.733\n 5   2024 Adelaide            5             0       228           303      0.752\n 6   2024 Adelaide            6             4       328           401      0.818\n 7   2024 Adelaide            7             4       403           479      0.841\n 8   2024 Adelaide            8             8       541           560      0.966\n 9   2024 Adelaide            9            12       619           608      1.02 \n10   2024 Adelaide           10            14       709           698      1.02 \n# ℹ 440 more rows\n# ℹ 1 more variable: ladder_position &lt;int&gt;\n\n\nThe output now shows Key: team [18], meaning we have 18 unique time series bundled together. This allows us to run one single model command to fit 18 separate models—one for each team!",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#visualizing-and-diagnosing-feasts-and-ggtime",
    "href": "03_time_series_r.html#visualizing-and-diagnosing-feasts-and-ggtime",
    "title": "3  The Toolkit: R for Time Series",
    "section": "3.2 Visualizing and Diagnosing: feasts and ggtime",
    "text": "3.2 Visualizing and Diagnosing: feasts and ggtime\nBefore modeling, you must understand the pattern of your data. The feasts package (Feature Extraction and Statistics for Time Series) and the ggtime extension for ggplot2 make this diagnosis easy. We’ll cover the interpretation of these plots and models in depth later; for now, focus on running the code to see what tools are available.\n\n3.2.1 Visualization with autoplot and ggtime\nThe autoplot() function, adapted from ggtime, is the quickest way to visualize a tsibble.\n\nautoplot(trump_approval_ts, approve) + \n  theme_minimal() + \n  labs(title = \"Trump Approval Rating\",\n       x = \"Date\",\n       y = \"Approval rating (%)\") + \n  scale_y_continuous(limits = c(0, 100))\n\n\n\n\n\n\n\nFigure 3.1: Mr Trump’s approval ratings since entering his second term in office.\n\n\n\n\n\nThis plot immediately reveals the central trend: a declining trajectory.\nWhen dealing with grouped data (like the AFL teams), autoplot automatically plots every series, making comparisons easy:\n\nautoplot(afl_ladder_ts, percentage) + \n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\", alpha = 0.6) +\n  theme_minimal() + \n  labs(title = \"AFL Team Score Percentage Over 2024 Season\",\n       x = \"Round\",\n       y = \"Scoring Percentage (For / Against)\") + \n  scale_y_continuous(labels = scales::percent_format(scale = 1))\n\n\n\n\n\n\n\nFigure 3.2: AFL teams’ score percentage across the 2024 regular season.\n\n\n\n\n\nThe plot shows 18 individual lines, allowing us to immediately see which teams (like the Sydney Swans, consistently above 100%) were successful and which (like North Melbourne, consistently below 100%) struggled.\n\n\n3.2.2 Diagnostic Tools with feasts\nThe most critical diagnostic plot in time series is the Seasonal Plot and the ACF (Autocorrelation Function) Plot.\n\nAutocorrelation Function (ACF): This plot tells you how correlated the variable is with its past values (lags). If the approval rating today is highly correlated with the approval rating 5 weeks ago, the ACF plot will show a strong spike at “Lag 5”. This helps us identify hidden dependencies and seasonality.\n\n\n# Use ACF to check for dependencies\ntrump_approval_ts |&gt; \n  ACF(approve) |&gt; # Calculate the AutoCorrelation Function\n  autoplot() +\n  labs(title = \"Autocorrelation in Trump Approval Rating\",\n       subtitle = \"High correlation means past values influence current values.\")\n\n\n\n\n\n\n\n\nThe initial spikes in the ACF plot tell us that approval ratings are highly correlated with the immediately preceding weeks, which is expected.\n\nDecomposition: Many series have a Trend (the long-term movement), a Seasonality (a repeating, predictable pattern, like higher sales in December), and a Remainder (the random noise). The feasts function model (which uses decomposition_model) helps separate these components, which is essential for accurate modeling.\n\nLet’s use the model function with STL() (Seasonal and Trend decomposition using Loess) to visualize these components:\n\n# Decompose the time series into its components\ntrump_approval_ts |&gt; \n  model(\n    decomposition = STL(approve) # Use STL to separate trend, seasonality, and remainder\n  ) |&gt; \n  components() |&gt; # Extract the components\n  autoplot() +\n  labs(title = \"Decomposition of Trump Approval Rating\")\n\n\n\n\n\n\n\n\nThe resulting plot shows four panels: the original observed data, the estimated Trend (the smooth, long-term movement), the Seasonal component (the weekly pattern, if any), and the Remainder (the residual noise not explained by trend or seasonality).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#archive",
    "href": "03_time_series_r.html#archive",
    "title": "3  The Toolkit: R for Time Series",
    "section": "3.5 Archive",
    "text": "3.5 Archive\nMuch better! The tsibble handles the “timing” of it all much more nicely than a standard tibble. By converting the date column to weekly data using the yearweek() function and the data set itself into a tsibble object, I have ensured that any visualizations or models I build using these data will be treated appropriately.\n\n3.5.1 Indexes\nThe column that records the time of your observations is referred to as the index. as_tibble() will often do a good job of guessing which column should be treated as your index, but you can specify it directly using the index argument. For examle:\n\ntrump_approval |&gt; \n  mutate(date = yearweek(date)) |&gt; \n  as_tibble(index = date)\n\n# A tibble: 38 × 2\n       date approve\n     &lt;week&gt;   &lt;dbl&gt;\n 1 2025 W42      40\n 2 2025 W41      39\n 3 2025 W40      40\n 4 2025 W39      39\n 5 2025 W37      41\n 6 2025 W36      41\n 7 2025 W38      39\n 8 2025 W32      41\n 9 2025 W35      41\n10 2025 W34      40\n# ℹ 28 more rows\n\n\ntsibble objects can handle many different frequencies:\n\n\n\n\n\nFrequency\nFunction\n\n\n\n\nYearly\nyear()\n\n\nQuarterly\nyearquarter()\n\n\nMonthly\nyearmonth()\n\n\nWeekly\nyearweek()\n\n\nDaily\nSee: as_date()\n\n\nSub-daily\nSee as_datetime()\n\n\n\n\n\n\n\n3.5.2 Keys\ntsibble objects are also very good at handling multiple groups within your data. For example, you might have data on all teams in a league. It can be useful to group those data by team.\nBelow is data on each AFL team’s performance throughout the 2024 season. For example, we have data on their position in the ladder throughout the season (ladder_position), the cumulative number of points they have scored (score_for) and have had scored against them (score_against).\nThere were 25 rounds in the regular season (excluding finals). Those rounds are my index. I want to track each team’s performance across the season. Therefore, my key is the team.\n\nafl_ladder &lt;- read_rds(here::here(\"data\", \"afl_ladder.rds\"))\n\nafl_ladder_ts &lt;- as_tsibble(afl_ladder, key = team, index = round_number)\nafl_ladder_ts\n\n# A tsibble: 450 x 8 [1]\n# Key:       team [18]\n   season team     round_number season_points score_for score_against percentage\n    &lt;dbl&gt; &lt;chr&gt;           &lt;int&gt;         &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n 1   2024 Adelaide            1             0         0             0      0    \n 2   2024 Adelaide            2             0        54            60      0.9  \n 3   2024 Adelaide            3             0       131           156      0.840\n 4   2024 Adelaide            4             0       165           225      0.733\n 5   2024 Adelaide            5             0       228           303      0.752\n 6   2024 Adelaide            6             4       328           401      0.818\n 7   2024 Adelaide            7             4       403           479      0.841\n 8   2024 Adelaide            8             8       541           560      0.966\n 9   2024 Adelaide            9            12       619           608      1.02 \n10   2024 Adelaide           10            14       709           698      1.02 \n# ℹ 440 more rows\n# ℹ 1 more variable: ladder_position &lt;int&gt;\n\n\nNotice that the tsibble object prints my key above the the data set. It recognizes that there are 18 different groups (teams) in my key. I now have 18 different time series (each team’s performance across the season) stored in one convenient data set. I can look at overall trends and compare the 18 different teams’ performance easily.\n\n\n3.5.3 Working with tsibble objects\nOn a tsibble, we can use all of the functions that you can use on a normal tibble or data.frame object. They are set up with the tidyverse in mind, so functions in that family work seamlessly.\nFor example, I can filter my data set of Mr Trump’s approval rating to look only at his approval in weeks five to 10 of his current term1:\n\nfilter(trump_approval_ts, date &lt;= yearweek(\"2025 W10\"))\n\n# A tsibble: 6 x 2 [1W]\n      date approve\n    &lt;week&gt;   &lt;dbl&gt;\n1 2025 W05      49\n2 2025 W06      46\n3 2025 W07      46\n4 2025 W08      50\n5 2025 W09      48\n6 2025 W10      48\n\n\nI can also quickly calculate Mr Trump’s average approval rating across his term in office:\n\nsummarise(trump_approval_ts, avg_approve = mean(approve))\n\n# A tsibble: 38 x 2 [1W]\n       date avg_approve\n     &lt;week&gt;       &lt;dbl&gt;\n 1 2025 W05          49\n 2 2025 W06          46\n 3 2025 W07          46\n 4 2025 W08          50\n 5 2025 W09          48\n 6 2025 W10          48\n 7 2025 W11          47\n 8 2025 W12          45\n 9 2025 W13          48\n10 2025 W14          46\n# ℹ 28 more rows",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#diagnostic-tools-with-feasts",
    "href": "03_time_series_r.html#diagnostic-tools-with-feasts",
    "title": "3  The Toolkit: R for Time Series",
    "section": "3.4 Diagnostic Tools with feasts",
    "text": "3.4 Diagnostic Tools with feasts",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  },
  {
    "objectID": "03_time_series_r.html#the-engine-the-fable-package",
    "href": "03_time_series_r.html#the-engine-the-fable-package",
    "title": "3  The Toolkit: R for Time Series",
    "section": "3.3 The Engine: The fable Package",
    "text": "3.3 The Engine: The fable Package\nThe fable package is the core modeling engine. It uses a clean, three-step pipeline that aligns perfectly with the tidyverse philosophy: model() -&gt; forecast() -&gt; autoplot(). Like decomposition, we will dive deep into specific forecasting models later. For now, focus on the workflow—how to fit a model, generate a forecast, and visualize the result.\n\n3.3.1 Step 1: model() - Fitting the Model\nThe model() function takes a tsibble and specifies the model(s) you want to fit using a formula. The output is a special mable (Model Table) object.\nWe can fit the simple linear trend model we saw in the last chapter using the TSLM() (Time Series Linear Model) function:\n\nfit_approval &lt;- trump_approval_ts |&gt; \n  model(\n    linear_trend = TSLM(approve ~ trend()),\n    # We can fit multiple models at once!\n    mean_model = MEAN(approve)\n  )\n\nfit_approval\n\n# A mable: 1 x 2\n  linear_trend mean_model\n       &lt;model&gt;    &lt;model&gt;\n1       &lt;TSLM&gt;     &lt;MEAN&gt;\n\n\nThe mable object now holds two fully trained models ready for forecasting.\n\n\n3.3.2 Step 2: forecast() - Generating Predictions\nThe forecast() function takes the mable object and tells it how far into the future (the horizon, or h) to predict.\n\n# Forecast approval ratings 5 weeks into the future\napproval_forecast &lt;- fit_approval |&gt; \n  forecast(h = \"5 weeks\")\n\napproval_forecast\n\n# A fable: 10 x 4 [1W]\n# Key:     .model [2]\n   .model           date\n   &lt;chr&gt;          &lt;week&gt;\n 1 linear_trend 2025 W43\n 2 linear_trend 2025 W44\n 3 linear_trend 2025 W45\n 4 linear_trend 2025 W46\n 5 linear_trend 2025 W47\n 6 mean_model   2025 W43\n 7 mean_model   2025 W44\n 8 mean_model   2025 W45\n 9 mean_model   2025 W46\n10 mean_model   2025 W47\n# ℹ 2 more variables: approve &lt;dist&gt;, .mean &lt;dbl&gt;\n\n\nThe output is a fable object (Forecast Table). Notice it provides the .mean (the point estimate) and a distribution for the prediction, allowing us to calculate the Prediction Interval (the range of plausible future values).\n\n\n3.3.3 Step 3: autoplot() - Visualizing the Forecast\nFinally, we plot the forecast using the original data and the autoplot() function.\n\n# Plotting the forecast table automatically includes the original data\napproval_forecast |&gt; \n  autoplot(trump_approval_ts, level = 80) + # Show an 80% prediction interval\n  theme_minimal() + \n  labs(title = \"Trump Approval Forecast: Linear Trend vs. Historical Mean\",\n       x = \"Date\",\n       y = \"Approval rating (%)\")\n\n\n\n\n\n\n\nFigure 3.3: Observed approval ratings with a 5-week forecast from two different models.\n\n\n\n\n\nThe resulting plot clearly shows the declining linear trend model and the flat line of the historical mean model, along with their respective 80% uncertainty cones (the shaded region). This visual comparison is the most powerful way to evaluate your models before deployment.\nBy mastering the tsibble, feasts, and fable pipeline, you gain a robust, modern, and efficient set of tools to tackle nearly any time series forecasting challenge, whether in political science or sports analytics.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Toolkit: R for Time Series</span>"
    ]
  }
]